{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutual information per time point\n",
    "Here, we apply the mutual information estimator defined in (Kraskov et al., 2004) and (Ross, 2014), to compute mutual information between peptide quality $Q$ and cytokines $\\mathbf{X}$, as a function of time. MI between peptide quality and cytokines is computed at each time point by aggregating time points over a sliding time window of 3 hours for better statistics. We use various quantities for the (vector) random variable $\\mathbf{X}$: each individual cytokine, the vector of 5 cytokines (IFN-$\\gamma$, IL-2, IL-17A, IL-6, TNF), each latent space variable (LS$_1$ or LS$_2$), the two latent space variables combined in a vector (LS$_1$, LS$_2$). \n",
    "\n",
    "Then, we compare to the mutual information between antigen quality and parameters of the constant velocity model, fitted on latent space time courses as a way to summarize the entire time kinetics of cytokines with a single vector of three real numbers ($v_0, t_0, \\theta$). \n",
    "\n",
    "We use a dataset (HighMI_1) which contains 4 replicates of the cytokine time series for each peptide at each concentration. This is the dataset shown in main figure 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Our own Python implementation of the MI algorithm\n",
    "from utils.discrete_continuous_info import discrete_continuous_info_fast, discrete_continuous_info_ref\n",
    "import utils.custom_pandas as cpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (2.25, 1.75)\n",
    "plt.rcParams[\"axes.labelsize\"] = 8.\n",
    "plt.rcParams[\"legend.fontsize\"] = 8.\n",
    "plt.rcParams[\"axes.labelpad\"] = 0.5\n",
    "plt.rcParams[\"xtick.labelsize\"] = 7.\n",
    "plt.rcParams[\"ytick.labelsize\"] = 7.\n",
    "plt.rcParams[\"legend.title_fontsize\"] = 8.\n",
    "plt.rcParams[\"axes.titlesize\"] = 8.\n",
    "plt.rcParams[\"font.size\"] = 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and project to latent space\n",
    "The HighMI_1 replicates were split in four separate files by our processing pipeline for compatibility with most former experiments that had only one replicate per condition. Here, we recombine those files to reform the whole dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cytokine data\n",
    "df_dict = {}\n",
    "for fi in os.listdir(os.path.join(\"data\", \"processed\")):\n",
    "    if fi.startswith(\"HighMI_1-\") and fi.endswith(\".hdf\"):\n",
    "        df_dict[fi[:-4]] = pd.read_hdf(os.path.join(\"data\", \"processed\", fi))\n",
    "\n",
    "df_wt = pd.concat(df_dict, names=[\"Data\"])\n",
    "df_wt = df_wt.xs(\"100k\", level=\"TCellNumber\", drop_level=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptides = [\"N4\", \"Q4\", \"T4\", \"V4\", \"G4\", \"E1\", \"A2\", \"Y3\", \"A8\"]\n",
    "concentrations = [\"1uM\",\"100nM\",\"10nM\",\"1nM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_min, df_max = pd.read_pickle(os.path.join(\"data\", \"trained-networks\", \"min_max-thomasRecommendedTraining.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cytokines = [\"IFNg\", \"IL-17A\", \"IL-2\", \"IL-4\", \"IL-6\", \"IL-10\", \"TNFa\"]\n",
    "times = np.arange(1, 73)\n",
    "print(cytokines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project to latent space and scale\n",
    "df = df_wt.unstack(\"Time\").loc[:, (\"integral\", cytokines, times)].stack(\"Time\")\n",
    "df_conc = df_wt.unstack(\"Time\").loc[:, (\"concentration\", cytokines, times)].stack(\"Time\")\n",
    "df = df.droplevel(\"Feature\", axis=1)\n",
    "df_conc = df_conc.droplevel(\"Feature\", axis=1)\n",
    "\n",
    "# Normalize\n",
    "df_min = df.min()\n",
    "df_max = df.max()\n",
    "df = (df - df_min)/(df_max - df_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add E1 from other datasets\n",
    "This peptide was not included in the HighMI_1 dataset because it consistently gives zero cytokine response, only measurement noise. Therefore, we import it from a few other datasets, since this null peptide category is important to get a proper estimate of mutual information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a few datasets containing E1\n",
    "df_dict = {}\n",
    "for fi in os.listdir(os.path.join(\"data\", \"processed\")):\n",
    "    if fi.startswith(\"Activation_2\") and fi.endswith(\".hdf\"):\n",
    "        df_dict[fi[:-4]] = (pd.read_hdf(os.path.join(\"data\", \"processed\", fi))\n",
    "            .xs(\"E1\", level=\"Peptide\", drop_level=False).xs(\"Naive\", level=\"ActivationType\", drop_level=True))\n",
    "    elif fi.startswith(\"CD25MutantTimeSeries\") and fi.endswith(\".hdf\"):\n",
    "        df_dict[fi[:-4]] = (pd.read_hdf(os.path.join(\"data\", \"processed\", fi))   # keep only OT-1 cell data\n",
    "            .xs(\"E1\", level=\"Peptide\", drop_level=False).xs(\"WT\", level=\"Genotype\", drop_level=True))\n",
    "    elif fi.startswith(\"PeptideComparison_OT1_Timeseries_18\") and fi.endswith(\".hdf\"):\n",
    "        df_dict[fi[:-4]] = (pd.read_hdf(os.path.join(\"data\", \"processed\", fi))\n",
    "            .xs(\"E1\", level=\"Peptide\", drop_level=False))\n",
    "\n",
    "df_data_e1 = pd.concat(df_dict, names=[\"Data\"])\n",
    "df_data_e1 = df_data_e1.loc[:, (slice(None), cytokines)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conc_e1 = df_data_e1.xs(\"concentration\", level=\"Feature\", axis=1)\n",
    "df_integ_e1 = df_data_e1.xs(\"integral\", level=\"Feature\", axis=1)\n",
    "df_integ_e1 = (df_integ_e1 - df_min)/(df_max - df_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conc = df_conc.append(df_conc_e1).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to compute MI over a sliding time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mi_slice(df, q, t, window, knn=3, speed=\"fast\"):\n",
    "    \"\"\" Compute the mutual information between the variable X in the columns of df\n",
    "    and the variable Q, a level in the index, in a time window centered at time t. \n",
    "    Time should be in the index too. Computes the MI between each feature and \n",
    "    the labels in q separately (sklearn's implementation does not handle \n",
    "    joint probability distributions). \n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): should have \"Time\" in its column levels \n",
    "            and q in its index. \n",
    "        q (str): the name of the index level to use as labels specifying\n",
    "            the values of the discrete RV. \n",
    "        t (float): the time on which the time window is centered. \n",
    "        window (float): duration of the time interval over which to \n",
    "            keep the samples. If a single time point is desired, use 0. \n",
    "        speed (str): either \"fast\" or \"slow\" (\"slow\" is ref. code)\n",
    "    \n",
    "    Returns:\n",
    "        mi (float): mutual information\n",
    "    \"\"\"\n",
    "    # Define the time window and slicer. Assuming the Time index is sorted. \n",
    "    tpts = np.array(df.index.get_level_values(\"Time\").unique())\n",
    "    tlo = tpts[np.searchsorted(tpts, t - window/2, side=\"left\")]\n",
    "    try:  # searchsorted can return the index next to the last; in that case, take the last\n",
    "        thi = tpts[np.searchsorted(tpts, t + window/2, side=\"right\")]\n",
    "    except IndexError:\n",
    "        thi = tpts[-1]\n",
    "    time_slice = slice(tlo, thi)\n",
    "    \n",
    "    # Slice the df with our custom function\n",
    "    df_t = cpd.xs_slice(df, \"Time\", time_slice, axis=0)\n",
    "    if isinstance(df_t, pd.Series):\n",
    "        df_t = df_t.to_frame()\n",
    "\n",
    "    # Extract the labels about which the data should inform\n",
    "    try:\n",
    "        mapping = {a:i for i, a in enumerate(df_t.index.get_level_values(q).unique())}\n",
    "        target = np.asarray(df_t.index.get_level_values(q).map(mapping))\n",
    "    except ValueError:\n",
    "        print(\"{} not in {}\".format(q, df_t.index))\n",
    "    \n",
    "    # Compute the MI!\n",
    "    if speed == \"fast\":\n",
    "        mi = discrete_continuous_info_fast(target, df_t.values, k=knn, base=2)\n",
    "    elif speed == \"slow\":\n",
    "        mi = discrete_continuous_info_ref(target, df_t.values, k=knn, base=2)\n",
    "    else:\n",
    "        raise ValueError(\"Speed '{}' not available\".format(speed))\n",
    "        \n",
    "    return mi\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the maximum possible MI\n",
    "# Function taken from the code for phi-evo simulations with cytokines\n",
    "# Can input the Peptide level values to this, it counts the number of \n",
    "# occurences of each label\n",
    "def entropy(xvals):\n",
    "    \"\"\" Builds the distribution and compute the entropy\n",
    "    of the sample xvals of some random variable X\n",
    "    Args:\n",
    "        xvals (list of int): list of sampled values of the X variable\n",
    "    Returns:\n",
    "        info (float): the entropy of the distribution from the sample, in bits\n",
    "    \"\"\"\n",
    "    possible_values = list(set(xvals))\n",
    "    mapping = {possible_values[i]:i for i in range(len(possible_values))}\n",
    "    probs = np.zeros(len(possible_values))\n",
    "    for x in xvals:\n",
    "        probs[mapping[x]] += 1\n",
    "    probs = probs / np.sum(probs)\n",
    "    # We are sure that no prob value is zero because we only considered possible values\n",
    "    info = np.sum(-probs * np.log(probs)) / np.log(2)  # in bits\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(my_array, target, condition):\n",
    "    \"\"\" Nice function by Akavall on StackOverflow:\n",
    "    https://stackoverflow.com/questions/17118350/how-to-find-nearest-value-that-is-greater-in-numpy-array\n",
    "    Page consulted Feb 10, 2019.\n",
    "    \"\"\"\n",
    "    diff = my_array - target\n",
    "    if condition == \"above\":\n",
    "        # We need to mask the negative differences and zero\n",
    "        # since we are looking for values above\n",
    "        mask = (diff <= 0)\n",
    "    elif condition == \"below\":\n",
    "        # We need to mask positive differences and zero\n",
    "        mask = (diff >= 0)\n",
    "    if np.all(mask):\n",
    "        return None # returns None if target is greater than any value\n",
    "    masked_diff = np.ma.masked_array(diff, mask)\n",
    "    return masked_diff.argmin()\n",
    "\n",
    "def compute_mi_timecourse(dfs, q, overlap, window, knn=3, names=None, speed=\"fast\"):\n",
    "    \"\"\" Compute the MI over time for each feature in each df. \n",
    "    \n",
    "    Args:\n",
    "        dfs (dict of pd.DataFrames): each df has one feature per column, and q in its index. \n",
    "        q (str): name of the index level to use as the discrete RV\n",
    "        overlap (bool): whether to allow the use of overlapping time windows\n",
    "            when computing the MI at succesive time points. \n",
    "        window (float): the time duration over which to take the samples to compute the\n",
    "            MI at one time point. Set to 0 if the distribution is to be based on single time points. \n",
    "        knn (int): number of nearest-neighbors to use. \n",
    "        speed (str): \"fast\" or \"slow\" (where \"slow\" is the reference code)\n",
    "        \n",
    "    Returns:\n",
    "        \n",
    "    \"\"\"      \n",
    "    # Set an order in which the dfs will be processed\n",
    "    names = list(dfs.keys())\n",
    "    \n",
    "    # Determine the upper bound on the MI\n",
    "    maximum_mi = entropy(dfs[names[0]].index.get_level_values(\"Peptide\"))\n",
    "\n",
    "    # Determine the times to consider for each df\n",
    "    time_values = [dfs[a].index.get_level_values(\"Time\").unique() for a in names]\n",
    "    # Define the central times to consider\n",
    "    if overlap or window == 0:  # we allow all times\n",
    "        times = time_values\n",
    "    else:  # we want different times at each evaluation\n",
    "        times = []\n",
    "        for t_array in time_values:\n",
    "            tstart = t_array[find_nearest(t_array, t_array[0] + window/2, \"above\")]\n",
    "            times.append(np.arange(tstart, t_array[-1], window))\n",
    "    \n",
    "    # Compute the MI at each selected time point, for each df\n",
    "    mi_courses = []  # Contains the MI time course of each df variable\n",
    "    for i in range(len(names)):\n",
    "        # Will be an array with one time per row, one feature per column\n",
    "        current_course = []\n",
    "        df = dfs[names[i]]\n",
    "        for t in times[i]:\n",
    "            current_course.append(compute_mi_slice(df, q, t=t, window=window, knn=knn, speed=speed))\n",
    "            if speed == \"slow\":\n",
    "                print(\"Time {} h done\".format(t))\n",
    "        mi_courses.append(np.array(current_course))\n",
    "    \n",
    "    df_mi_courses = pd.concat([pd.Series(mi_courses[i], index=times[i]) for i in range(len(times))], \n",
    "                             keys=names, names=[\"Variable\", \"Time\"])\n",
    "    print(df_mi_courses.index.names)\n",
    "    df_mi_courses = df_mi_courses.unstack(\"Variable\")\n",
    "    \n",
    "    return df_mi_courses, maximum_mi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute MI for individual cytokines and the vector of five cytokines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_variables_dfs = {\n",
    "    \"all cytokines\": df_conc\n",
    "}\n",
    "all_variables_dfs.update({c:df_conc[c] for c in cytokines})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_variables_dfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of NN: 3 neighbors times length of time window.  \n",
    "df_mi_time, max_mi = compute_mi_timecourse(all_variables_dfs, q=\"Peptide\", overlap=False, \n",
    "                      window=3, knn=3*3, speed=\"fast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=df_mi_time.stack(\"Variable\").reset_index(), x=\"Time\", y=0, hue=\"Variable\", kind=\"line\", height=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save all results for further plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the theoretical maximal MI (entropy of Q) to the dataframe, for reference. \n",
    "# This is simply log_2(number of peptides). \n",
    "df_mi_time[\"MaxMI\"] = np.ones(df_mi_time.shape[0])*np.nan\n",
    "df_mi_time[\"MaxMI\"].iloc[-1] = max_mi\n",
    "df_mi_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to save; data used for main figure 1E\n",
    "# df_mi_time.to_hdf(\"output/miStatistics-HighMI_1-all-cytokines.hdf\", key=\"df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MI estimation for latent space variables\n",
    "LS$_1$ and LS$_2$ taken together preserve all information available in the five cytokines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_coefs = np.load(os.path.join(\"data\", \"trained-networks\", \"mlp_coefs-thomasRecommendedTraining.npy\"))\n",
    "df_min, df_max = pd.read_pickle(os.path.join(\"data\", \"trained-networks\", \"min_max-thomasRecommendedTraining.pkl\"))\n",
    "df2 = df.append(df_integ_e1)\n",
    "df2 = cpd.xs_slice(df2, \"Cytokine\", df_min.index.get_level_values(\"Cytokine\").unique().tolist(), axis=1)\n",
    "# Rename Data to Replicate, add Data level\n",
    "lvl_names = df2.index.names\n",
    "df2.index = df2.index.set_names([\"Replicate\"]+lvl_names[1:])\n",
    "df2 = df2.rename({a:str(i) for i, a in enumerate(df2.index.get_level_values(\"Replicate\").unique())})\n",
    "df2 = pd.concat({\"HighMI_1\": df2}, names=[\"Data\"])\n",
    "df2 = df2.sort_index()\n",
    "df_proj = pd.DataFrame(np.dot(df2, mlp_coefs), index=df2.index, columns=[\"Node 1\", \"Node 2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_variables_dfs_latent = {\n",
    "    \"LS1\": df_proj[\"Node 1\"],\n",
    "    \"LS2\": df_proj[\"Node 2\"],\n",
    "    \"2 LS\": df_proj\n",
    "}\n",
    "df_mi_latent, max_mi_latent = compute_mi_timecourse(all_variables_dfs_latent, q=\"Peptide\",\n",
    "                       overlap=False, window=3, knn=3*3, speed=\"fast\")\n",
    "print(df_mi_latent.max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=df_mi_latent.stack(\"Variable\").reset_index(), x=\"Time\", y=0, hue=\"Variable\", kind=\"line\", height=2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MI estimation for $v_0$, $t_0$, $\\theta$\n",
    "Fit the constant velocity parameters on each time series, then compute MI between that description of cytokine time kinetics and antigen quality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltspcyt.scripts.sigmoid_ballistic import return_param_and_fitted_latentspace_dfs\n",
    "fit_vars = {\"Constant velocity\":[\"v0\", \"t0\", \"theta\", \"vt\"], \n",
    "           \"Sigmoid_freealpha\":[\"a0\", \"t0\", \"theta\", \"v1\", \"alpha\", \"beta\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1_key = (slice(None), slice(None), slice(None), \"E1\")\n",
    "df2.loc[e1_key, :] = df2.loc[e1_key, :] + 0.01*np.random.normal(size=df2.loc[e1_key].size).reshape(df2.loc[e1_key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting\n",
    "choice_model = \"Constant velocity\"\n",
    "regul_rate = 1.0\n",
    "\n",
    "# Here, we need to reject negative v2v1 slopes, this improves the constant velocity fit for mouse1-replicate4\n",
    "ret = return_param_and_fitted_latentspace_dfs(df_proj, choice_model, reg_rate=regul_rate, reject_neg_slope=True)\n",
    "df_params, df_compare, df_hess, df_v2v1 = ret\n",
    "\n",
    "nparameters = len(fit_vars[choice_model])\n",
    "peptides = [a for a in peptides if a in df_params.index.get_level_values(\"Peptide\").unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_choice = fit_vars[choice_model][:3]\n",
    "pep_palette_order = [\"N4\", \"Q4\", \"T4\", \"V4\", \"G4\", \"E1\", \"A2\", \"Y3\"]\n",
    "palette = sns.color_palette(n_colors=len(pep_palette_order))\n",
    "pep_palette = {pep:palette[i] for i, pep in enumerate(pep_palette_order)}\n",
    "hue_order = [a for a in pep_palette_order if a in df_params.index.get_level_values(\"Peptide\").unique()]\n",
    "sns.pairplot(data=df_params.iloc[:, :4].reset_index(), hue=\"Peptide\", hue_order=hue_order, \n",
    "             palette=[pep_palette.get(a) for a in hue_order], \n",
    "             vars=var_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove clear outliers\n",
    "df_params = df_params.loc[df_params.index.isin([\"V4\"], level=\"Peptide\")*df_params[\"theta\"] < np.pi/2]\n",
    "df_params = df_params.loc[df_params.index.isin([\"E1\"], level=\"Peptide\")*df_params[\"theta\"] < np.pi/2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_choice = fit_vars[choice_model][:3]\n",
    "vals = df_params[var_choice].values\n",
    "pep_map = {peptides[i]:i for i in range(len(peptides))}\n",
    "target = df_params.index.get_level_values(\"Peptide\").map(pep_map)\n",
    "# Number of knn: equals to number used before (3) per time point, for fair comparison\n",
    "mi_v0t0theta = discrete_continuous_info_fast(target, vals, k=3, base=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result\n",
    "print(mi_v0t0theta)  # bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
