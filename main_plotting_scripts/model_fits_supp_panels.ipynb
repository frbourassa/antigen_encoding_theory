{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary panels showing how latent space models fit data\n",
    "\n",
    "To run this notebook, you need:\n",
    "- To have run `fit_latentspace_models.ipynb` for each model and saved the results in `results/fits/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "import os, sys\n",
    "main_dir_path = os.path.abspath('../')\n",
    "sys.path.insert(0, main_dir_path)\n",
    "\n",
    "from utils.plotting_fits import (add_hue_size_style_legend, timecourse_smallplots, \n",
    "    latentspace_smallplot, barplots_levels, paramspace_smallplots, create_cmap_seed, \n",
    "    create_midseeded_clist, add_legend_subtitles_huemaps, create_labeling)\n",
    "import utils.custom_pandas as custom_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcParams for all plots\n",
    "plt.rcParams['savefig.transparent'] = True\n",
    "\n",
    "param_formatting_dict = {\n",
    "    \"theta\": r\"\\theta\", \n",
    "    \"vt\": r\"v_{t2}\", \n",
    "    \"t0\": r\"t_0\",\n",
    "    \"tau0\": r\"\\tau_0\",\n",
    "    \"v0\": r\"v_0\", \n",
    "    \"a0\": r\"a_0\", \n",
    "    \"v1\": r\"v_{t1}\", \n",
    "    \"alpha\": r\"\\alpha\", \n",
    "    \"beta\": r\"\\beta\", \n",
    "    \"gamma\": r\"\\gamma\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing unavailable time points\n",
    "By default, the df_compare dataframes (with spline and model time series at every hour) extend time series to 72 hours. If an experiment did not extend to 72 hours, missing time points are set equal to the last available time point. We need to remove those artifical time points, which do not match the data, to have a truthful estimate of the residuals and the average residuals when we group per certain levels (e.g. per time). \n",
    "\n",
    "I have compiled elsewhere, with a small script, a the list of the last available time point for each experiment. It is saved in the JSON file ``fit_results/last_time_point_per_experiment.json``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(main_dir_path, \"results\", \"fits\", \"last_time_point_per_experiment.json\"), \"r\") as h:\n",
    "    last_times_dict = json.load(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call this function on each df_compare that I import\n",
    "def remove_artificial_times(df, max_t_dict):\n",
    "    full_df = {}\n",
    "    for d in df.index.get_level_values(\"Data\").unique():\n",
    "        try:\n",
    "            tmax = max_t_dict[d]\n",
    "        except KeyError:\n",
    "            print(\"Could not find last experimental time for {}\".format(d))\n",
    "            tmax = 72\n",
    "        df_d = df.xs(d, level=\"Data\", axis=0)\n",
    "        df_d = df_d.loc[df_d.index.get_level_values(\"Time\").astype(float) <= tmax]\n",
    "        full_df[d] = df_d\n",
    "    return pd.concat(full_df, names=[\"Data\"], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant velocity model\n",
    "Show $N_i(t)$, $N_1$ vs $N_2$, $n_i(t)$. \n",
    "Also show parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_height = 2.1\n",
    "plots_width = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare_velo = pd.read_hdf(os.path.join(main_dir_path, \"results\", \"fits\", \n",
    "                            \"df_compare_Constant_velocity_reg10_selectdata.hdf\"))\n",
    "df_compare_velo = remove_artificial_times(df_compare_velo, last_times_dict)\n",
    "dset_velo = \"Activation_Timeseries_1\"\n",
    "df_compare_velo = custom_pd.xs_slice(df_compare_velo, name=\"Peptide\", lvl_slice=[\"N4\", \"Q4\", \"T4\", \"V4\"], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_compare_velo.index.get_level_values(\"Data\").unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrals\n",
    "fig, [ax1, ax2, axleg, leg] = timecourse_smallplots(\n",
    "    custom_pd.xs_slice(df_compare_velo.xs(dset_velo, level=\"Data\", axis=0)\n",
    "                    .xs(\"100k\", level=\"TCellNumber\", axis=0)\n",
    "                    .xs(\"integral\", level=\"Feature\", axis=0),\n",
    "                 name=\"Concentration\", lvl_slice=[\"1uM\", \"10nM\"], axis=0),\n",
    "    feat_name=\"LS\", maxwidth=1.5, do_leg=False, \n",
    "    fontsize=6, handlelength=2.)\n",
    "fig.set_size_inches(plots_width*3/4, plots_height)\n",
    "fig.tight_layout(h_pad=0.5)\n",
    "# fig.savefig(os.path.join(main_dir_path, \"figures\", \"supp\", \"constant_velocity_integrals_latent_timecourses.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N1 vs N2\n",
    "fig, [ax1, axleg, leg] = latentspace_smallplot(\n",
    "    df_compare_velo.xs(dset_velo, level=\"Data\", axis=0)\n",
    "                        .xs(\"100k\", level=\"TCellNumber\", axis=0)\n",
    "                        .xs(\"integral\", level=\"Feature\", axis=0),\n",
    "    feat_name=\"LS\", maxwidth=1.5, do_leg=True, \n",
    "    fontsize=6, handlelength=2.)\n",
    "leg.get_frame().set_linewidth(0.0)\n",
    "fig.set_size_inches(plots_width, plots_height)\n",
    "fig.tight_layout()\n",
    "# fig.savefig(os.path.join(main_dir_path, \"figures\", \"supp\", \"constant_velocity_integrals_latent_trajectories.pdf\"))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "df_params_velo = pd.read_hdf(os.path.join(main_dir_path, \"results\", \"fits\", \"df_params_Constant_velocity_reg10_selectdata.hdf\"))\n",
    "\n",
    "# Remove concentrations below 1 nM\n",
    "df_params_velo = custom_pd.xs_slice(df_params_velo, name=\"Concentration\", \n",
    "                                   lvl_slice=[\"1uM\", \"300nM\", \"100nM\", \"30nM\", \"10nM\", \n",
    "                                             \"3nM\", \"1nM\"], axis=0)\n",
    "\n",
    "# Correct column names so they are formatted to math\n",
    "param_name_map = {a:a for a in df_params_velo.columns}\n",
    "param_name_map.update(param_formatting_dict)\n",
    "df_params_velo.columns = df_params_velo.columns.map(param_name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [axes, axleg, leg] = paramspace_smallplots(\n",
    "    df_params_velo.loc[df_params_velo.index.isin([\"80k\", \"100k\"], level=\"TCellNumber\")], \n",
    "    hue_level_name=\"Peptide\", style_level_name=None, size_level_name=\"Concentration\", \n",
    "    do_leg=True, fontsize=6, handlelength=1, maxsize=5., ncol=2)\n",
    "leg.get_frame().set_linewidth(0.0)\n",
    "fig.set_size_inches(plots_width*1.75, plots_height*2)\n",
    "fig.tight_layout(w_pad=0.5, h_pad=0.5)\n",
    "#fig.savefig(os.path.join(main_dir_path, \"figures\", \"supp\", \"param_plots_constant_velocity_100k.pdf\"), \n",
    "#    transparent=True, bbox_inches=\"tight\", bbox_extra_artists=(leg,))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Force model with matching, fixed alpha\n",
    "We want to show the fits of $n_1(t)$, $n_2(t)$ in more detail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare_fixalpha = pd.read_hdf(os.path.join(main_dir_path, \"results\", \"fits\", \n",
    "                                    \"df_compare_Sigmoid_reg04_selectdata.hdf\"))\n",
    "df_compare_fixalpha = remove_artificial_times(df_compare_fixalpha, last_times_dict)\n",
    "dset_fixalpha = \"Activation_Timeseries_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_compare_fixalpha.index.get_level_values(\"Data\").unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrals\n",
    "fig, [ax1, ax2, axleg, leg] = timecourse_smallplots(\n",
    "    custom_pd.xs_slice(df_compare_fixalpha.xs(dset_fixalpha, level=\"Data\", axis=0)\n",
    "                .xs(\"100k\", level=\"TCellNumber\", axis=0)\n",
    "                .xs(\"integral\", level=\"Feature\", axis=0), \n",
    "            name=\"Concentration\", lvl_slice=[\"1uM\", \"10nM\"], axis=0), \n",
    "    feat_name=\"LS\", maxwidth=1.5, do_leg=False, \n",
    "    fontsize=6, handlelength=2.)\n",
    "fig.set_size_inches(plots_width*3/4, plots_height)\n",
    "fig.tight_layout(h_pad=0.5)\n",
    "# fig.savefig(os.path.join(main_dir_path, \"figures\", \"supp\", \"sigmoid_fixalpha_integrals_latent_timecourses.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N1 vs N2\n",
    "fig, [ax1, axleg, leg] = latentspace_smallplot(\n",
    "    custom_pd.xs_slice(df_compare_fixalpha.xs(dset_fixalpha, level=\"Data\", axis=0)\n",
    "                        .xs(\"100k\", level=\"TCellNumber\", axis=0)\n",
    "                        .xs(\"integral\", level=\"Feature\", axis=0),\n",
    "        name=\"Peptide\", lvl_slice=[\"N4\", \"Q4\", \"T4\", \"V4\"], axis=0), \n",
    "    feat_name=\"LS\", maxwidth=1.5, do_leg=True, \n",
    "    fontsize=6, handlelength=2.)\n",
    "leg.get_frame().set_linewidth(0.0)\n",
    "fig.set_size_inches(plots_width, plots_height)\n",
    "fig.tight_layout()\n",
    "# fig.savefig(os.path.join(main_dir_path, \"figures\", \"supp\", \"sigmoid_fixalpha_integrals_latent_trajectories.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "df_params_fixalpha = pd.read_hdf(os.path.join(main_dir_path, \"results\", \"fits\", \"df_params_Sigmoid_reg04_selectdata.hdf\"))\n",
    "\n",
    "# Remove concentrations below 1nM\n",
    "df_params_fixalpha = custom_pd.xs_slice(df_params_fixalpha, name=\"Concentration\", \n",
    "                                   lvl_slice=[\"1uM\", \"300nM\", \"100nM\", \"30nM\", \"10nM\", \n",
    "                                             \"3nM\", \"1nM\"], axis=0)\n",
    "\n",
    "# Correct column names so they are formatted to math\n",
    "param_name_map = {a:a for a in df_params_fixalpha.columns}\n",
    "param_name_map.update(param_formatting_dict)\n",
    "df_params_fixalpha.columns = df_params_fixalpha.columns.map(param_name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [axes, axleg, leg] = paramspace_smallplots(\n",
    "    df_params_fixalpha.loc[df_params_fixalpha.index.isin([\"80k\", \"100k\"], level=\"TCellNumber\")][[\"a_0\", r\"\\tau_0\", r\"\\theta\", r\"v_{t1}\"]],  \n",
    "    hue_level_name=\"Peptide\", style_level_name=None, size_level_name=\"Concentration\", \n",
    "    do_leg=True, maxsize=5., fontsize=6, handlelength=1, ncol=2)\n",
    "leg.get_frame().set_linewidth(0.0)\n",
    "fig.set_size_inches(plots_width*1.75, plots_height*2)\n",
    "fig.tight_layout(w_pad=0.5, h_pad=0.5)\n",
    "#fig.savefig(os.path.join(main_dir_path, \"figures\", \"supp\", \"param_plots_sigmoid_fixalpha_100k_4paramsshown.pdf\"),\n",
    "#           transparent=True, bbox_inches=\"tight\", bbox_extra_artists=(leg,))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Force model with matching, free alpha\n",
    "What we want to show is mostly the parameter space colored per T cell number, because the fits are essentially identical, but the parameter space takes care of T cell number separately from other peptide-related attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare_freealpha = pd.read_hdf(os.path.join(main_dir_path, \"results\", \"fits\", \n",
    "                                    \"df_compare_Sigmoid_freealpha_reg04_selectdata.hdf\"))\n",
    "df_compare_freealpha = remove_artificial_times(df_compare_freealpha, last_times_dict)\n",
    "dset_freealpha = \"Activation_Timeseries_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_compare_freealpha.index.get_level_values(\"Data\").unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrals\n",
    "fig, [ax1, ax2, axleg, leg] = timecourse_smallplots(\n",
    "    custom_pd.xs_slice(df_compare_freealpha.xs(dset_freealpha, level=\"Data\", axis=0)\n",
    "                .xs(\"100k\", level=\"TCellNumber\", axis=0)\n",
    "                .xs(\"integral\", level=\"Feature\", axis=0), \n",
    "            name=\"Concentration\", lvl_slice=[\"1uM\", \"10nM\"], axis=0),\n",
    "    feat_name=\"LS\", maxwidth=1.5, do_leg=False, \n",
    "    fontsize=6, handlelength=2.)\n",
    "fig.set_size_inches(plots_width*3/4, plots_height)\n",
    "fig.tight_layout(h_pad=0.5)\n",
    "#fig.savefig(os.path.join(main_dir_path, \"figures\", \"supp\", \"sigmoid_freealpha_integrals_latent_timecourses.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N1 vs N2\n",
    "fig, [ax1, axleg, leg] = latentspace_smallplot(\n",
    "    custom_pd.xs_slice(df_compare_freealpha.xs(dset_freealpha, level=\"Data\", axis=0)\n",
    "                        .xs(\"100k\", level=\"TCellNumber\", axis=0)\n",
    "                        .xs(\"integral\", level=\"Feature\", axis=0),\n",
    "        name=\"Peptide\", lvl_slice=[\"N4\", \"Q4\", \"T4\", \"V4\"], axis=0), \n",
    "    feat_name=\"LS\", maxwidth=1.5, do_leg=True, \n",
    "    fontsize=6, handlelength=2.)\n",
    "leg.get_frame().set_linewidth(0.0)\n",
    "fig.set_size_inches(plots_width, plots_height)\n",
    "fig.tight_layout()\n",
    "#fig.savefig(os.path.join(main_dir_path, \"figures\", \"supp\", \n",
    "#    \"sigmoid_freealpha_integrals_latent_trajectories.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "df_params_freealpha = pd.read_hdf(os.path.join(main_dir_path, \"results\", \"fits\", \n",
    "                                    \"df_params_Sigmoid_freealpha_reg04_selectdata.hdf\"))\n",
    "\n",
    "# Remove concentrations below 1nM\n",
    "df_params_freealpha = custom_pd.xs_slice(df_params_freealpha, name=\"Concentration\", \n",
    "                                   lvl_slice=[\"1uM\", \"300nM\", \"100nM\", \"30nM\", \"10nM\", \n",
    "                                             \"3nM\", \"1nM\"], axis=0)\n",
    "\n",
    "# Correct column names so they are formatted to math\n",
    "param_name_map = {a:a for a in df_params_freealpha.columns}\n",
    "param_name_map.update(param_formatting_dict)\n",
    "df_params_freealpha.columns = df_params_freealpha.columns.map(param_name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_params_freealpha.index.get_level_values(\"Data\").unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [axes, axleg, leg] = paramspace_smallplots(\n",
    "    df_params_freealpha.loc[df_params_freealpha.index.isin([\"80k\", \"100k\"], level=\"TCellNumber\")][[\"a_0\", r\"\\tau_0\", r\"\\theta\", r\"v_{t1}\"]], \n",
    "    hue_level_name=\"Peptide\", style_level_name=None, size_level_name=\"Concentration\", \n",
    "    do_leg=True, maxsize=5., fontsize=6, handlelength=1, ncol=2)\n",
    "leg.get_frame().set_linewidth(0.0)\n",
    "fig.set_size_inches(plots_width*1.75, plots_height*2)\n",
    "fig.tight_layout(w_pad=0.5, h_pad=0.5)\n",
    "#fig.savefig(os.path.join(main_dir_path, \"figures\", \"supp\", \"param_plots_sigmoid_freealpha_100k_4paramsshown.pdf\"), \n",
    "#            transparent=True, bbox_inches=\"tight\", bbox_extra_artists=(leg,))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of models for concentration\n",
    "Choose the same data set for all compared models, but a different dataset from above just to show that the models do not fit a single experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_conc = \"TCellNumber_OT1_Timeseries_7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant velocity model\n",
    "fig, [ax1, ax2, axleg, leg] = timecourse_smallplots(\n",
    "    custom_pd.xs_slice(df_compare_velo.xs(dset_conc, level=\"Data\", axis=0)\n",
    "                        .xs(\"100k\", level=\"TCellNumber\", axis=0)\n",
    "                        .xs(\"concentration\", level=\"Feature\", axis=0),\n",
    "        name=\"Concentration\", lvl_slice=[\"1uM\", \"10nM\"], axis=0), \n",
    "    feat_name=\"ls\", maxwidth=1.5, do_leg=False, \n",
    "    fontsize=6, handlelength=2.)\n",
    "# leg.get_frame().set_linewidth(0.0)\n",
    "fig.set_size_inches(plots_width*3/4, plots_height)\n",
    "fig.tight_layout(h_pad=0.5)\n",
    "#fig.savefig(os.path.join(main_dir_path, \"figures\", \"supp\", \"constant_velocity_concentrations_latent_timecourses.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed alpha model\n",
    "fig, [ax1, ax2, axleg, leg] = timecourse_smallplots(\n",
    "    custom_pd.xs_slice(df_compare_fixalpha.xs(dset_conc, level=\"Data\", axis=0)\n",
    "                .xs(\"100k\", level=\"TCellNumber\", axis=0)\n",
    "                .xs(\"concentration\", level=\"Feature\", axis=0),\n",
    "        name=\"Concentration\", lvl_slice=[\"1uM\", \"10nM\"], axis=0),\n",
    "    feat_name=\"ls\", maxwidth=1.5, do_leg=False, \n",
    "    fontsize=6, handlelength=2.)\n",
    "# leg.get_frame().set_linewidth(0.0)\n",
    "fig.set_size_inches(plots_width*3/4, plots_height)\n",
    "fig.tight_layout(h_pad=0.5)\n",
    "#fig.savefig(os.path.join(main_dir_path, \"figures\", \"supp\", \n",
    "#            \"sigmoid_fixalpha_concentrations_latent_timecourses.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free alpha model\n",
    "fig, [ax1, ax2, axleg, leg] = timecourse_smallplots(\n",
    "    custom_pd.xs_slice(df_compare_freealpha.xs(dset_conc, level=\"Data\", axis=0)\n",
    "                .xs(\"100k\", level=\"TCellNumber\", axis=0)\n",
    "                .xs(\"concentration\", level=\"Feature\", axis=0), \n",
    "        name=\"Concentration\", lvl_slice=[\"1uM\", \"10nM\"], axis=0), \n",
    "    feat_name=\"ls\", maxwidth=1.5, do_leg=True, \n",
    "    fontsize=6, handlelength=2.)\n",
    "leg.get_frame().set_linewidth(0.0)\n",
    "fig.set_size_inches(plots_width, plots_height)\n",
    "fig.tight_layout(h_pad=0.5)\n",
    "#fig.savefig(os.path.join(main_dir_path, \"figures\", \"supp\", \n",
    "#            \"sigmoid_freealpha_concentrations_latent_timecourses.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit residuals on concentrations and integrals\n",
    "Per peptide, averaged over all conditions, on each node.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_residuals(df, gby_extras=()):\n",
    "    pr = \"Processing type\"\n",
    "    df_res = ((df.xs(\"Splines\", level=pr) - df.xs(\"Fit\", level=pr))**2\n",
    "             ).groupby([\"Feature\", *gby_extras]).mean()\n",
    "    return df_res.unstack(\"Feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute residuals for integrals and concentrations\n",
    "groupby_extras=(\"Time\",)\n",
    "df_res_velo = compute_residuals(df_compare_velo, gby_extras=groupby_extras)\n",
    "df_res_fixalpha = compute_residuals(df_compare_fixalpha, gby_extras=groupby_extras)\n",
    "df_res_freealpha = compute_residuals(df_compare_freealpha, gby_extras=groupby_extras)\n",
    "print(df_res_velo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res_all = pd.concat({\"Constant \\nvelocity\":df_res_velo, \n",
    "                        \"Matching, \\nfixed \" + r\"$\\alpha$\": df_res_fixalpha, \n",
    "                        \"Matching, \\nfree \" + r\"$\\alpha$\": df_res_freealpha}, \n",
    "                       axis=0, names=[\"Model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for integrals\n",
    "def plot_residuals_feature(df_all, feat=\"integral\", colmap=\"cubehelix\", do_leg=True, **kwargs):\n",
    "    \"\"\" kwargs are passed to axes.legend(). \"\"\"\n",
    "    fig = plt.figure()\n",
    "    if do_leg:\n",
    "        gs = fig.add_gridspec(nrows=2, ncols=4)\n",
    "    else:\n",
    "        gs = fig.add_gridspec(nrows=2, ncols=3)\n",
    "    axes = [fig.add_subplot(gs[0, :3])]\n",
    "    axes.append(fig.add_subplot(gs[1, :3], sharex=axes[0]))\n",
    "    times = df_all.index.get_level_values(\"Time\").unique().map(float)\n",
    "    if isinstance(colmap, str):\n",
    "        colors = [sns.set_hls_values(a, s=1) for a in sns.color_palette(colmap, 4)]\n",
    "        # colors = sns.color_palette(colmap, 4)\n",
    "    elif isinstance(colmap, list):\n",
    "        colors = colmap\n",
    "    else:\n",
    "        raise TypeError(\"{} not a supported type for colmap\".format(type(colmap)))\n",
    "    styles = [\"-\", \":\", \"--\", \"-.\"]\n",
    "    for i, mod in enumerate(df_all.index.get_level_values(\"Model\").unique()):\n",
    "        axes[0].plot(times, df_all.loc[mod, (\"Node 1\", feat)], label=mod, color=colors[i],\n",
    "                    ls=styles[i], lw=2.)\n",
    "        axes[1].plot(times, df_all.loc[mod, (\"Node 2\", feat)], label=mod, color=colors[i], \n",
    "                    ls=styles[i], lw=2.)\n",
    "\n",
    "    # Adjust size, labels, etc. \n",
    "    axes[1].set_xlabel(\"Time [h]\", size=8)\n",
    "    lbl = \"ls\" if feat==\"concentration\" else \"LS\"\n",
    "    for i in range(2):\n",
    "        axes[i].tick_params(axis=\"both\", length=2., width=0.5, labelsize=6.)\n",
    "        axes[i].set_yscale(\"log\")\n",
    "        axes[i].set_ylabel(r\"Residuals$^2$ ${}_{}$\".format(lbl, i+1), size=8)\n",
    "    # Add a legend\n",
    "    if do_leg:\n",
    "        kwargs2 = dict(bbox_to_anchor=(0, 0), loc=\"lower left\")\n",
    "        kwargs2.update(kwargs)\n",
    "        legax = fig.add_subplot(gs[:, -1])\n",
    "        leg = legax.legend(*axes[1].get_legend_handles_labels(), **kwargs2)\n",
    "        legax.set_axis_off()\n",
    "    else:\n",
    "        legax = None\n",
    "        \n",
    "    return fig, axes, legax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = [sns.set_hls_values(a, s=1) for a in sns.color_palette(\"cubehelix\", 4)][-2::-1]\n",
    "fig, axes, legax = plot_residuals_feature(df_res_all, feat=\"integral\", colmap=cmap, do_leg=False)\n",
    "fig.set_size_inches(plots_width*3/4, plots_height)\n",
    "fig.tight_layout(h_pad=0.5)\n",
    "#fig.savefig(os.path.join(main_dir_path, \"figures\", \"supp\", \"residuals_integrals.pdf\"), transparent=True)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes, legax = plot_residuals_feature(df_res_all, feat=\"concentration\", colmap=cmap, \n",
    "                                          do_leg=True, fontsize=6, handlelength=2., labelspacing=1., \n",
    "                                         bbox_to_anchor=(0, -0.12))\n",
    "fig.set_size_inches(plots_width, plots_height)\n",
    "fig.tight_layout(h_pad=0.5)\n",
    "legax.get_legend().get_frame().set_linewidth(0.0)\n",
    "#fig.savefig(os.path.join(main_dir_path, \"figures\", \"supp\", \"residuals_concentrations.pdf\"), transparent=True, \n",
    "#            bbox_extra_artists=(legax.get_legend(),), bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of T cell number on fits of different models â€“ removed from paper\n",
    "We did not discuss this at length, but fitting the $\\alpha$ parameter in the constant force model with matching improves fit residuals for T cell numbers different from 100k initial cells. Also, fitting $\\alpha$ makes the $a_0$ vs $\\tau_0$ correlation collapse onto a single diagonal, while that correlation has different slopes for different T cell numbers when $\\alpha$ is fixed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_extras = (\"TCellNumber\",)\n",
    "tcnums = [\"100k\", \"30k\", \"10k\", \"3k\"]\n",
    "dsets = ['Activation_TCellNumber_1']\n",
    "\n",
    "df_res_all_tcn = pd.concat({\n",
    "    \"Matching, \\nfixed \" + r\"$\\alpha$\": \n",
    "        compute_residuals(df_compare_fixalpha.loc[(dsets, tcnums), :], groupby_extras), \n",
    "    \"Matching, \\nfree \" + r\"$\\alpha$\": \n",
    "        compute_residuals(df_compare_freealpha.loc[(dsets, tcnums), :], groupby_extras)\n",
    "    }, names=[\"Model\"], axis=0)\n",
    "df_res_all_tcn = df_res_all_tcn.groupby([\"TCellNumber\", \"Model\"]).mean()\n",
    "df_res_all_tcn.columns = df_res_all_tcn.columns.set_names([\"Node\", \"Feature\"])\n",
    "df_res_all_tcn = df_res_all_tcn.stack(\"Node\").unstack(\"Node\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = df_res_all.index.get_level_values(\"Model\").unique()\n",
    "colors_models = [sns.set_hls_values(a, s=1) for a in sns.color_palette(\"cubehelix\", len(all_models))]\n",
    "colormap_models = {all_models[i]:colors_models[i] for i in range(len(all_models))}\n",
    "\n",
    "fig, axes, legax = barplots_levels(\n",
    "    df_res_all_tcn[[(\"concentration\", \"Node 1\"), (\"concentration\", \"Node 2\")]]*1e5, \n",
    "    hue_lvl=\"Model\", x_lvl=\"TCellNumber\", groupwidth=0.7, hue_map=colormap_models, hue_reverse=False)\n",
    "\n",
    "# Rectify the y axis labels and title\n",
    "axes[0].set_ylabel(r\"$10^5 \\, \\times$ Res${}^2$\", size=8)\n",
    "axes[0].set_xlabel(\"T cell number\", size=8)\n",
    "for i in range(1, len(df_res_all_tcn.index.get_level_values(\"Model\").unique())):\n",
    "    axes[i].set_ylabel(\"\")\n",
    "    axes[i].set_xlabel(\"T cell number\", size=8)\n",
    "axes[0].set_title(\"Node 1\", fontsize=8)\n",
    "axes[1].set_title(\"Node 2\", fontsize=8)\n",
    "\n",
    "fig.set_size_inches(4.25, 1.8)  # Smaller nice size: 3.5, 1.6\n",
    "fig.tight_layout(h_pad=0.5, w_pad=0.5)\n",
    "# fig.savefig(os.path.join(main_dir_path, \"figures\", \"supp\", \"residuals_tcellnumber_alpha.pdf\"), \n",
    "#        transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter pairplots colored per T cell number\n",
    "Take 1 (maybe 2 very similar) datasets where we can see how fitting alpha makes the a0 vs tau0 curves collapse on top of each other. \n",
    "\n",
    "- Show a_0 vs tau_0 for fixed and free alpha; \n",
    "    - Add linear r quadratic regression fits for each TCN? \n",
    "- Show a KDE plot of the $\\alpha$ parameter\n",
    "- Try to respect the color map used for each model, rather than the color map viridis for T cell number? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare colors: fixed alpha\n",
    "# colors_fixed_alpha = create_midseeded_clist(colormap_models.get(\"Matching, \\nfixed \" + r\"$\\alpha$\"), len(tcnums))\n",
    "colors_fixed_alpha = create_cmap_seed(colormap_models.get(\"Matching, \\nfixed \" + r\"$\\alpha$\"), \n",
    "                                      n_colors = len(tcnums), light=False)\n",
    "#colors_fixed_alpha = sns.light_palette(colormap_models.get(\"Matching, \\nfixed \" + r\"$\\alpha$\"), n_colors=len(tcnums)+1)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare colors: free alpha\n",
    "#colors_free_alpha = create_midseeded_clist(colormap_models.get(\"Matching, \\nfree \" + r\"$\\alpha$\"), len(tcnums), max_l=0.92, min_l=0.5)\n",
    "colors_free_alpha = create_cmap_seed(colormap_models.get(\"Matching, \\nfree \" + r\"$\\alpha$\"), \n",
    "                                      n_colors = len(tcnums), light=False)\n",
    "#colors_free_alpha = sns.light_palette(colormap_models.get(\"Matching, \\nfree \" + r\"$\\alpha$\"), n_colors=len(tcnums)+1)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_params_freealpha = df_params_freealpha.astype(np.float64)\n",
    "df_params_fixalpha = df_params_fixalpha.astype(np.float64)\n",
    "dsets = ['Activation_TCellNumber_1', \"TCellNumber_OT1_Timeseries_7\", \"Activation_TCellNumber_2\", \n",
    "        \"TCellNumber_1\", \"TCellNumber_2\"]\n",
    "dsets = dsets[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_params_plot_linear_fit(df, dsets, params, tcns, colors, ax):\n",
    "    markers = [\"o\", \"s\", \"o\", \"X\", \"P\", \"1\", \"2\", \"3\", \"4\", \"8\", \"*\", \"D\"]\n",
    "    parx, pary = params[0], params[1]\n",
    "    for i, tcn in enumerate(tcns):\n",
    "        x, y = df.loc[(dsets, tcn), parx], df.loc[(dsets, tcn), pary]\n",
    "        j = 0\n",
    "        for pep in df.loc[dsets].index.get_level_values(\"Peptide\").unique():\n",
    "            ax.plot(x.xs(pep, level=\"Peptide\").values, y.xs(pep, level=\"Peptide\").values, \n",
    "                    color=colors[i], ls=\"none\", marker=markers[j], ms=4)\n",
    "            j += 1\n",
    "\n",
    "        # Quadratic fit to emphasize the collapse or lack thereof. Force through zero\n",
    "        coefs = np.polynomial.polynomial.polyfit(x.values, y.values, deg=[1, 2], rcond=None, full=False)\n",
    "        xrange = np.arange(x.min(), x.max()+0.025, 0.05)\n",
    "        ax.plot(xrange, np.polynomial.polynomial.polyval(xrange, coefs), ls=\"-\", lw=1., \n",
    "                color=colors[i], label=tcn)\n",
    "    return ax, coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First and second plot: tau_0 vs a_0 for fixed alpha\n",
    "fig, axes = plt.subplots(2, 2, sharex=\"col\")\n",
    "fig.set_size_inches(4.25, 3.25)\n",
    "\n",
    "ax, coefs = pairwise_params_plot_linear_fit(df_params_fixalpha, dsets, \n",
    "                        [\"a_0\", r\"\\tau_0\"], tcnums, colors_fixed_alpha, axes[0, 0])\n",
    "\n",
    "# Second plot: same thing, for fixed alpha\n",
    "ax, coefs = pairwise_params_plot_linear_fit(df_params_freealpha, dsets, \n",
    "                        [\"a_0\", r\"\\tau_0\"], tcnums, colors_free_alpha, axes[1, 0])\n",
    "\n",
    "# Third plot: KDE of alpha\n",
    "sns.kdeplot(data=df_params_freealpha.loc[dsets].reset_index(), x=r\"\\alpha\", hue=\"TCellNumber\", palette=colors_free_alpha, \n",
    "            ax=axes[1, 1], legend=False, fill=True)\n",
    "\n",
    "# Label plots properly\n",
    "for i in range(2):\n",
    "    axes[i, 0].set_ylabel(r\"$\\tau_0$ [-]\", size=9)\n",
    "    axes[i, 0].set_xlabel(r\"$a_0$ [-]\", size=9)\n",
    "    axes[i, 0].tick_params(axis=\"both\", width=0.5, length=2.5, labelsize=7)\n",
    "axes[1, 1].set_xlabel(r\"$\\alpha$ [-]\", size=9)\n",
    "axes[1, 1].set_ylabel(\"Density [-]\", size=9)\n",
    "axes[1, 1].tick_params(axis=\"both\", width=0.5, length=2.5, labelsize=7)\n",
    "\n",
    "\n",
    "# Legend\n",
    "models = list(df_res_all_tcn.index.get_level_values(\"Model\").unique())\n",
    "models.sort(key=lambda x: x.count(\"free\"))\n",
    "for i in range(len(models)):\n",
    "    models[i].replace(\"\\n\", \"\")\n",
    "legd = add_legend_subtitles_huemaps(models, hue_maps=[\n",
    "            {tcnums[i]:colors_fixed_alpha[i] for i in range(len(tcnums))}, \n",
    "            {tcnums[i]:colors_free_alpha[i] for i in range(len(tcnums))}], \n",
    "        ax=axes[0, 1], hue_levels_order=tcnums[::-1],\n",
    "        fontsize=8, ncol=2, borderaxespad=-2.5, loc=\"upper left\", \n",
    "        bbox_to_anchor=(0.05, 0.65), frameon=False, columnspacing=-4.)\n",
    "\n",
    "axes[0, 1].set_axis_off()\n",
    "fig.tight_layout()\n",
    "# fig.savefig(os.path.join(main_dir_path, \"figures\", \"supp\", \"a0-tau0_slope_alphaKDE_{}.pdf\".format(dsets[0])), transparent=True)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revision figure: more examples of LS1 and LS2 fits\n",
    "Just show multiple $LS_1$, $LS_2$ plots, fits vs splines. For the force model with matching. \n",
    "\n",
    "Use the ensemble of datasets I called  \"selectdata\" : theese are 14 datasets with time series for naive CD8+ OT-1 T cells with no known major experimental problem. \n",
    "\n",
    "Of course, there is variability, we know that some look less like the most reliable ones, but the models fit anyways. Reconstruction would be harder, but even in that case, I tried fitting a decoder (linear regression with quadratic terms tanh integrals included) on those 15 datasets, and the R^2 was > 0.90, which is pretty good considering that variability and some minor flaws exhibited by those decoders when we use them to reconstruct cytokines from model trajectories. \n",
    "\n",
    "Also a plot of total reconstruction error over time; use relative error and average over all time series in a dataset to be able to compare. Make a bar graph with one bar per experiment.  \n",
    "Could compare constant velocity model and force model: two bars per dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check datasets available, should be the same for both models. \n",
    "print(df_compare_freealpha.index.get_level_values(\"Data\").unique())\n",
    "print(df_compare_velo.index.get_level_values(\"Data\").unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To properly rank peptides  according to antigenicity\n",
    "peptide_ranks = {\"N4\":13, \"Q4\":12, \"T4\":11, \"V4\":10, \"G4\":9, \"E1\":8,\n",
    "              \"A2\":7, \"Y3\":6, \"A8\":5, \"Q7\":4}\n",
    "\n",
    "def choose_traj(df, randomgen, size=1, per_lvl=\"Peptide\", do_not_sample=()):\n",
    "    \"\"\" Group df rows per_lvl and select <size> samples of the available indices.  \n",
    "    do_not_sample specifies which levels should not be considered as separate samples, \n",
    "    e.g. time if we want to select a certain number of time series. \n",
    "    \"\"\"\n",
    "    df2 = df\n",
    "    # Stack levels to ignode\n",
    "    for lvl in do_not_sample:\n",
    "        df2 = df2.unstack(lvl)\n",
    "    # Select size conditions per group\n",
    "    try:\n",
    "        df_sampled = df2.groupby(per_lvl).sample(n=size, replace=False, random_state=randomgen)\n",
    "    except ValueError:  # Too few sample available for some peptide\n",
    "        df_sampled = {}\n",
    "        for ind, gp in df2.groupby(per_lvl):\n",
    "            df_sampled[ind] = gp.loc[ind].sample(n=min(size, gp.shape[0]), replace=False, random_state=randomgen)\n",
    "        df_sampled = pd.concat(df_sampled, names=[per_lvl], axis=0)\n",
    "    # Stack back ignored levels. \n",
    "    for lvl in do_not_sample:\n",
    "        df_sampled = df_sampled.stack(lvl)\n",
    "    return df_sampled\n",
    "\n",
    "\n",
    "# Function used to change TCellNumber when 100k not available\n",
    "def get_closest_tcn(target, choices):\n",
    "    # First, convert each choice to integer\n",
    "    choices_int = []\n",
    "    map_units = {\"k\":1000, \"M\":int(1e6), \"\":1}\n",
    "    # Function to map to each string\n",
    "    def str_to_int_number(s):\n",
    "        n = \"\"\n",
    "        units = \"\"\n",
    "        for c in s:\n",
    "            if c.isnumeric() or c == \".\":\n",
    "                n += c\n",
    "            elif c.isalpha():\n",
    "                units += c\n",
    "        base = float(n)\n",
    "        factor = map_units.get(units, 1)\n",
    "        return base*factor\n",
    "    # Then, find index of closest integer number of T cells\n",
    "    choices_int = list(map(str_to_int_number, choices))\n",
    "    choices_int = np.asarray(choices_int)\n",
    "    target = str_to_int_number(target)\n",
    "    where = np.argmin(np.abs(choices_int - target))\n",
    "    # Return string at the index of choice closest to target\n",
    "    return choices[where]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make one big plot with 12 datasets (showing one HighMI_1 repeat)\n",
    "# So this involves 3*4*2 plots, times 2 models. \n",
    "# Let's do this: randomly select 6 of 12 datasets; if HighMI_1 selected pick one replicate\n",
    "# Then make four columns with two groups of two, one per dataset, and six rows, three groups of two, on\n",
    "# Rows alternate between LS1 and LS2 this way. \n",
    "# Randomly sample two conditions per peptide for each dataset (else graph is too crowded)\n",
    "\n",
    "# Add spacer column in the middle\n",
    "# No need for spacer rows because the title on top of each plot will solve it. \n",
    "# But need one thin row at the top for titles of groups of 2 columns.\n",
    "def example_fits_plots(feat, dfv, dff, seed=249824358):\n",
    "    nrows = 3  # Number of rows of datasets\n",
    "    ncols = 2  # Number of columns of datasets\n",
    "    n_dsets = nrows * ncols    # Number of datasets to show\n",
    "    n_subrows = 2  # Number of variables\n",
    "    n_subcols = 2  # Number of models\n",
    "    fig = plt.figure()\n",
    "    # Add an extra column for legends...\n",
    "    gs = fig.add_gridspec(nrows=nrows*(n_subrows+1), ncols=ncols*n_subcols+1+1, \n",
    "                          height_ratios=[0.15, 1.15, 1.15]*nrows, \n",
    "                          width_ratios=[1.2, 1.2, 0.1, 1.2, 1.2, 0.3])\n",
    "    fig.set_size_inches(ncols*n_subcols*1.25+0.3, nrows*n_subrows*1.15)\n",
    "\n",
    "    # Legend axis\n",
    "    axleg = fig.add_subplot(gs[:, -1])\n",
    "    axleg.set_axis_off()\n",
    "\n",
    "    # 3D array of plots, indexed data, node, model\n",
    "    axes = np.zeros([n_dsets, n_subrows, n_subcols], dtype=object)\n",
    "    for i in range(n_dsets):\n",
    "        irow, icol = i // ncols, i % ncols\n",
    "        for j in range(n_subrows):\n",
    "            for k in range(n_subcols):\n",
    "                sharex = None if (j == 0 and i < ncols) else axes[icol, 0, k]\n",
    "                sharey = None if (k == 0 and i == 0) else axes[0, j, 0]\n",
    "                #ax = axes0[irow*(n_subrows+1)+j+1, icol*(n_subcols+1) +  + k]\n",
    "                ax = fig.add_subplot(gs[irow*(n_subrows+1)+j+1, icol*(n_subcols+1) + k], \n",
    "                                     sharex=sharex, sharey=sharey)\n",
    "                axes[i, j, k] = ax\n",
    "\n",
    "\n",
    "    # Select datasets randomly\n",
    "    rgen = np.random.default_rng(seed=seed)\n",
    "    dsets_available = df_compare_velo.index.get_level_values(\"Data\").unique().to_list()\n",
    "    # Remove the dataset that we already plotted in the supplementary figure above\n",
    "    dsets_available.remove(dset_freealpha)\n",
    "    for i in range(1, 5):\n",
    "        dsets_available.remove(\"HighMI_1-{}\".format(i))\n",
    "    dsets_available.append(\"HighMI_1\")\n",
    "    dataset_selection = rgen.choice(dsets_available, size=n_dsets, replace=False)\n",
    "    # If HighMI_1 is there, randomly select one of the replicates\n",
    "    for i in range(len(dataset_selection)):\n",
    "        if dataset_selection[i] == \"HighMI_1\":\n",
    "            dataset_selection[i] = \"HighMI_1-{}\".format(rgen.choice(np.arange(1, 5), size=1)[0])\n",
    "    print(dataset_selection)\n",
    "\n",
    "\n",
    "    # Set axis off for other subplots and replace with titles where appropriate\n",
    "    title_axes = np.zeros([nrows, ncols], dtype=object)\n",
    "    for i in range(nrows):\n",
    "        for k in range(ncols):\n",
    "            dset_idx = i*ncols + k\n",
    "            title_axes[i, k] = fig.add_subplot(gs[i*(n_subrows+1), k*(n_subcols+k):k*(n_subcols+k)+n_subcols])\n",
    "            title_axes[i, k].set_axis_off()\n",
    "            dsetlbl = dataset_selection[dset_idx]\n",
    "            if len(dsetlbl) > 20:\n",
    "                dsetlbl = dsetlbl[:18] + \"...\" + dsetlbl[-2:]\n",
    "            title_axes[i, k].annotate(dsetlbl,  xy=(0.5, 1.0), \n",
    "                xycoords=\"axes fraction\", va=\"top\", ha=\"center\", fontsize=9)\n",
    "\n",
    "\n",
    "    # Finally, we are ready to plot the model vs data time series\n",
    "    for k in range(n_dsets):\n",
    "        axesk = axes[k]\n",
    "        # Select the dataset, peptides and TCellNumber to plot\n",
    "        tcn = \"100k\"\n",
    "        df_velo_plot = (df_compare_velo.xs(dataset_selection[k], level=\"Data\")\n",
    "                        .xs(feat, level=\"Feature\", axis=0))\n",
    "        # In case 100k is not available, take closest, e.g. 80k in TCellNumber_1\n",
    "        try:\n",
    "            df_velo_plot = df_velo_plot.xs(tcn, level=\"TCellNumber\", axis=0)\n",
    "        except KeyError:\n",
    "            tcn = get_closest_tcn(tcn, df_velo_plot.index.get_level_values(\"TCellNumber\").unique().to_list())\n",
    "            df_velo_plot = df_velo_plot.xs(tcn, level=\"TCellNumber\", axis=0)\n",
    "        df_velo_plot = df_velo_plot.loc[df_velo_plot.index.isin([\"N4\", \"Q4\", \"T4\", \"V4\"], level=\"Peptide\")]\n",
    "\n",
    "        df_force_plot = (df_compare_freealpha.xs(dataset_selection[k], level=\"Data\")\n",
    "                         .xs(feat, level=\"Feature\", axis=0))\n",
    "        df_force_plot = df_force_plot.loc[df_force_plot.index.isin([\"N4\", \"Q4\", \"T4\", \"V4\"], level=\"Peptide\")]\n",
    "        df_force_plot = df_force_plot.xs(tcn, level=\"TCellNumber\", axis=0)\n",
    "\n",
    "        # Select only two time series per peptide\n",
    "        next_seed = rgen.integers(int(2**32) - 1, size=1)\n",
    "        df_velo_plot = choose_traj(df_velo_plot, next_seed, size=2, \n",
    "                            per_lvl=\"Peptide\", do_not_sample=[\"Time\", \"Processing type\"])\n",
    "        df_force_plot = choose_traj(df_force_plot, next_seed, size=2, \n",
    "                            per_lvl=\"Peptide\", do_not_sample=[\"Time\", \"Processing type\"])\n",
    "\n",
    "        legend_info = create_labeling(df_velo_plot, maxwidth=1.25)\n",
    "        hue_level_name, hues = legend_info[0]\n",
    "        size_level_name, sizes = legend_info[1]\n",
    "        style_level_name, styles = legend_info[2]\n",
    "\n",
    "        # Plot each LS variable for each model\n",
    "        for j in range(n_subcols):\n",
    "            df_feature = df_velo_plot if j == 0 else df_force_plot\n",
    "            model = \"Velocity model\" if j == 0 else \"Force model\"\n",
    "            df_feature = df_feature.unstack(\"Time\")\n",
    "            index_names = list(df_feature.index.names)\n",
    "            hue_pos = index_names.index(hue_level_name)\n",
    "            if size_level_name != \"\":\n",
    "                size_pos = index_names.index(size_level_name)\n",
    "            else:\n",
    "                size_pos = None\n",
    "            if style_level_name != \"\":\n",
    "                style_pos = index_names.index(style_level_name)\n",
    "            else:\n",
    "                style_pos = None\n",
    "            axesk[0, j].set_title(model, fontsize=8)\n",
    "            # Plot each line\n",
    "            for key in df_feature.index:\n",
    "                times = df_feature.loc[key].index.get_level_values(\"Time\").unique()\n",
    "                times = sorted(times, key=float)\n",
    "                times_f = np.asarray(times)\n",
    "                n1_vals = df_feature.loc[key, \"Node 1\"].loc[times]\n",
    "                n2_vals = df_feature.loc[key, \"Node 2\"].loc[times]\n",
    "                # Load the color, linestyle, size corresponding to this key\n",
    "                hue = hues.get(key[hue_pos])\n",
    "                siz = sizes.get(key[size_pos]) if size_pos is not None else 2.\n",
    "                sty = styles.get(key[style_pos]) if style_pos is not None else \"-\"\n",
    "                axesk[0, j].plot(times_f, n1_vals, color=hue, lw=siz, ls=sty)\n",
    "                axesk[1, j].plot(times_f, n2_vals, color=hue, lw=siz, ls=sty)\n",
    "\n",
    "            # Label axes if necessary\n",
    "            ax1.tick_params(which=\"both\", length=1.5, width=0.5, labelsize=6.)\n",
    "\n",
    "            # More formatting, set off tick labels if shared axes, etc.\n",
    "            # y axes labels and tick labels\n",
    "            if j == 0 and (k % ncols) == 0:\n",
    "                lbl = \"LS\" if feat == \"integral\" else \"ls\"\n",
    "                axesk[0, j].set_ylabel(r\"${}_1(t)$ (a.u.)\".format(lbl), size=8)\n",
    "                plt.setp(axesk[0, j].get_yticklabels(), size=7)\n",
    "                axesk[1, j].set_ylabel(r\"${}_2(t)$ (a.u.)\".format(lbl), size=8)\n",
    "                plt.setp(axesk[1, j].get_yticklabels(), size=7)\n",
    "            else:\n",
    "                # Use setp, which loops over labels to set them all to invisible\n",
    "                plt.setp(axesk[0, j].get_yticklabels(), visible=False)\n",
    "                plt.setp(axesk[1, j].get_yticklabels(), visible=False)\n",
    "\n",
    "            # x axes labels and tick labels: hide all except last row\n",
    "            if (k // n_subrows) == nrows - 1:\n",
    "                axesk[1, j].set_xlabel(\"Time (h)\", size=8)\n",
    "                axesk[1, j].set_xticks([0, 24, 48, 72])\n",
    "                axesk[1, j].set_xticklabels([0, 24, 48, 72])\n",
    "                plt.setp(axesk[1, j].get_xticklabels(), size=7)\n",
    "                axesk[0, j].set_xlabel(\"\")\n",
    "                plt.setp(axesk[0, j].get_xticklabels(), visible=False)\n",
    "            else:\n",
    "                axesk[0, j].set_xlabel(\"\")\n",
    "                axesk[1, j].set_xlabel(\"\")\n",
    "                plt.setp(axesk[1, j].get_xticklabels(), visible=False)\n",
    "                plt.setp(axesk[0, j].get_xticklabels(), visible=False)\n",
    "            if k == 0:\n",
    "                leg = add_hue_size_style_legend(\n",
    "                    axleg, hues, sizes, styles, size_level_name,\n",
    "                    style_level_name, hue_sort_key=peptide_ranks.get, \n",
    "                    frameon=False, fontsize=7)\n",
    "    fig.tight_layout(w_pad=0.2, h_pad=0.2)\n",
    "    return fig, axes, axleg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes, axleg = example_fits_plots(\"integral\", df_compare_velo, df_compare_freealpha)\n",
    "#fig.savefig(os.path.join(main_dir_path, \"figures\", \"fits\", \"revision_fig_more_model_fits_integrals.pdf\"), \n",
    "#    transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes, axleg = example_fits_plots(\"concentration\", df_compare_velo, df_compare_freealpha, seed=1009191)\n",
    "#fig.savefig(os.path.join(main_dir_path, \"figures\", \"fits\", \"revision_fig_more_model_fits_concentrations.pdf\"), \n",
    "#    transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of residuals\n",
    "\n",
    "Residuals are normalized by the range of the variable ($LS_1$, $LS_2$, $ls_1$, $ls_2$) in each dataset.  This is really the only non-arbitrary measurement of the latent space variables' magnitude. \n",
    "Because it is also arbitrary whether nodes are centered at zero or off-origin; the latter would reduce the relative error artificially. This is especially true since we are in log-scale; the zero just gives an indication of the scale, it is not an absolute. So, residuals of uniform magnitude in log scale, no matter the value of the log, are actually residuals proportional to the signal already. \n",
    "\n",
    "We consider signed residuals rather than absolute (RMS or squared) residuals because:\n",
    "  - We want to show that the model is not biased towards fitting consistently lower or higher values than the data (splines). So, the mean should be close to zero\n",
    "  - We want to show the typical deviation above and below the spline data; they should also be similar. \n",
    "\n",
    "We normalize the residuals of the LS variable by its range (max - min across conditions) in each dataset, because:\n",
    "  - The distribution of the LS variable itself above or below zero is arbitrary (rotations of the latent space are irrelevant to antigen encoding and the amount of information in the trajectories). \n",
    "  - The usual relative error (error divided by the value of the LS variable) blows up when the LS variable cross zero; the model is not supposed to fit better near zero values of a LS variable than elsewhere. A \"small\" error on the LS variable values when it is crossing zero is acceptable; intuitively, \"small\" refers to the full range that this variable will span over time. \n",
    "  - The location of the zero is arbitrary, just like, e.g., the choice of the origin of a coordinate system to describe real ballistic motions; it does not represent a null observable quantity. \n",
    "  - The LS variables are derived from log-transformed physical quantities (concentrations), so residuals that would be uniform across values of the LS variables are actually proportional to the magnitude of the variable in linear scale, corresponding to uniform relative error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_residuals_signed(df):\n",
    "    pr = \"Processing type\"\n",
    "    return df.xs(\"Splines\", level=pr) - df.xs(\"Fit\", level=pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All squared residuals per time series\n",
    "df_res_velo = compute_residuals_signed(df_compare_velo)\n",
    "df_res_matching = compute_residuals_signed(df_compare_freealpha)\n",
    "\n",
    "# Normalization factor of each feature's residuals, per dataset: the range of each LS variable. \n",
    "range_lsLS_per_dset = (df_compare_velo.xs(\"Splines\", level=\"Processing type\").groupby([\"Data\", \"Feature\"]).max()\n",
    "                       - df_compare_velo.xs(\"Splines\", level=\"Processing type\").groupby([\"Data\", \"Feature\"]).min())\n",
    "range_lsLS_per_dset = range_lsLS_per_dset.unstack(\"Feature\")\n",
    "print(range_lsLS_per_dset.mean(axis=0))\n",
    "\n",
    "# Statistics of residuals normalized per dataset. Will create box plots and scatter plots\n",
    "df_res_velo_norm = df_res_velo.unstack(\"Feature\") / range_lsLS_per_dset * 100  # in %\n",
    "df_res_matching_norm = df_res_matching.unstack(\"Feature\") / range_lsLS_per_dset * 100  # in %\n",
    "print(df_res_velo_norm.groupby(\"Data\").mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nice box plot plus histogram of those residuals. One boxplot per LS variable; this gives four in total\n",
    "# Put legend to the right (same legend for all four)\n",
    "# Make one row for LS, one row for ls.\n",
    "\n",
    "# First, prepare a nicely formatted DataFrame to slice\n",
    "plotDf = pd.concat({\"Constant velocity\":df_res_velo_norm, \n",
    "                    \"Force w/ matching\":df_res_matching_norm}, names=[\"Model\"])\n",
    "def feature_renamer(tup):\n",
    "    node, feat = tup \n",
    "    base = r\"$LS_{}$\" if feat == \"integral\" else r\"$ls_{}$\"\n",
    "    return base.format(\"{\" + str(node[-1]) + \"}\")\n",
    "plotDf = plotDf.drop([\"PeptideComparison_OT1_Timeseries_20\"], level=\"Data\")  # Same as NewPeptide... \n",
    "plotDf = plotDf.sort_index(axis=1, level=0, ascending=False)\n",
    "plotDf = plotDf.stack(\"Feature\").unstack(\"Feature\").sort_index(axis=1, level=\"Feature\", ascending=False)\n",
    "plotDf.columns = pd.Index(list(map(feature_renamer, plotDf.columns.to_list())), name=\"Variable\")\n",
    "plotDf = plotDf.stack(\"Variable\")\n",
    "plotDf.name = \"Residuals\"\n",
    "datasets_to_int_map = {a:i for i, a in enumerate(plotDf.index.get_level_values(\"Data\").unique())}\n",
    "#int_to_datasets_map = {i:a for a, i in datasets_to_int_map.items()}  # To write names in the labels\n",
    "plotDf = plotDf.rename(index=datasets_to_int_map, level=\"Data\")\n",
    "# Make sure of the order of index levels\n",
    "plotDf = plotDf.reorder_levels(\n",
    "    [\"Model\", \"Data\", 'TCellNumber', 'Peptide', 'Concentration', 'Time', 'Variable'])\n",
    "\n",
    "# Prepare figure\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(2.5*2 + 0.5, 2.25*2)\n",
    "gs = fig.add_gridspec(nrows=2, ncols=3, width_ratios=[1.0, 1.0, 0.3])\n",
    "axes = np.zeros([2, 2], dtype=object)\n",
    "\n",
    "# First and last, same colors as in supp. fig of residuals\n",
    "colors_models = [sns.set_hls_values(a, s=1) for a in sns.color_palette(\"cubehelix\", 4)][-2::-1]\n",
    "colors_models = colors_models[::2][::-1]\n",
    "models_order = [\"Force w/ matching\", \"Constant velocity\"]\n",
    "\n",
    "# Loop over features\n",
    "# C-order : LS1, LS2, ls1, ls2\n",
    "nice_ls_names = [r\"$LS_{1}$\", r\"$LS_{2}$\", r\"$ls_{1}$\", r\"$ls_{2}$\"]\n",
    "assert len(nice_ls_names) == len(plotDf.index.get_level_values(\"Variable\").unique())\n",
    "for i in range(len(nice_ls_names)):\n",
    "    # Create new axis\n",
    "    sharey = axes[i // 2, 0] if i % 2 == 1 else None\n",
    "    sharex = axes[0, i % 2] if i // 2 == 1 else None\n",
    "    ax = fig.add_subplot(gs[i // 2, i % 2], sharey=sharey, sharex=sharex)\n",
    "    axes.flat[i] = ax\n",
    "    # Use sns.boxplot on this axis\n",
    "    g = sns.boxplot(data=plotDf.xs(nice_ls_names[i], level=\"Variable\", axis=0).reset_index(), \n",
    "                x=\"Data\", y=\"Residuals\", hue=\"Model\", palette=colors_models, ax=ax, \n",
    "                whis=(5, 95), hue_order=models_order,\n",
    "                linewidth=0.75, showfliers=False, width=0.7,\n",
    "                flierprops=dict(markersize=1., markeredgewidth=0.1))\n",
    "    ax.axhline(0.0, ls=\":\", lw=1.0, zorder=0, color=\"grey\")\n",
    "    g.legend_.remove()\n",
    "    \n",
    "    # Title: variable\n",
    "    ax.set_title(nice_ls_names[i], fontsize=10, y=0.98)\n",
    "    \n",
    "    # Hide or show tick and axes labels when appropriate\n",
    "    # y labels and ticks\n",
    "    if i % 2 == 0:\n",
    "        ax.set_ylabel(ax.get_ylabel() + \" / range (%)\", size=10)\n",
    "        plt.setp(ax.get_yticklabels(), fontsize=8)\n",
    "    else:\n",
    "        ax.set_ylabel(\"\")\n",
    "        plt.setp(ax.get_yticklabels(), visible=False)\n",
    "    # x labels and ticks\n",
    "    ax.set_xticklabels([str(i+1) if i % 2 == 0 else \"\" \n",
    "                        for i in range(len(ax.get_xticklabels()))])\n",
    "    if i >= len(nice_ls_names) - 2:\n",
    "        ax.set_xlabel(\"Dataset\", size=10)\n",
    "        plt.setp(ax.get_xticklabels(), fontsize=8)\n",
    "    else:\n",
    "        ax.set_xlabel(\"\")\n",
    "        plt.setp(ax.get_xticklabels(), visible=False)\n",
    "\n",
    "# Manual legend: two Rectangles, one per color      \n",
    "legax = fig.add_subplot(gs[:, -1])\n",
    "legax.set_axis_off()\n",
    "models_order2 = []\n",
    "for lbl in models_order:\n",
    "    models_order2.append(\" \".join(lbl.split(\" \")[:-1]) + \"\\n\" + lbl.split(\" \")[-1]) \n",
    "legax.legend(handles=[mpl.patches.Rectangle((0, 0), 1, 1, color=colors_models[0], label=models_order[0]), \n",
    "                      mpl.patches.Rectangle((0, 0), 1, 1, color=colors_models[1], label=models_order[1])], \n",
    "             labels=models_order2, frameon=False, loc=\"upper left\", bbox_to_anchor=(-0.4, 0.9), \n",
    "             fontsize=8, title=\"Model\", title_fontsize=10, borderaxespad=0.3, borderpad=0.3)\n",
    "\n",
    "# Set titles: LS1, LS2, ls1, or ls2\n",
    "fig.tight_layout(w_pad=0.5, h_pad=0.5)\n",
    "#fig.savefig(os.path.join(main_dir_path, \"figures\", \"fits\", \"revision_fig_model_fits_residuals_boxplots.pdf\"), \n",
    "#    transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
