{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruct cytokine time courses from data projected in latent space\n",
    "\n",
    "The best reconstructions are obtained with the following procedure. \n",
    "In addition to latent space concentrations, we include linear terms in $\\tanh({N_1 \\ \\bar{N}_1})$ and $\\tanh({N_2/\\bar{N}_2})$ in the reconstruction,  with quadratic concentration terms too. The constants $\\bar{N}_1$ and $\\bar{N}_2$ are normalization constants, taken to be the average value of $N_1$ and $N_2$ over all times and conditions in the training data. The purpose of including tanh functions is to saturate the value of integrals, so they can sustain the reconstructed cytokines at late times without causing artificial continuous increase in the cytokine values. \n",
    "\n",
    "In other words, we reconstruct cytokine $c_i$ with the following combination of terms: \n",
    "\n",
    "$$ c_i = Q_{i1} n_1 + Q_{i2} n_2 + Q_{i3} n_1^2 + Q_{i4} n_2^2 + Q_{i5} n_1 n_2  + Q_{i6} \\tanh{(N_1/\\bar{N}_1)} + Q_{i7} \\tanh{(N_2/\\bar{N}_2)}$$\n",
    "\n",
    "The $5\\times 7$ matrix $Q_{ij}$ is fitted by linear least-squares regression on the non-linear terms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltspcyt.scripts.adapt_dataframes import sort_SI_column\n",
    "from ltspcyt.scripts.neural_network import import_WT_output\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltspcyt.scripts.reconstruction import (train_reconstruction, plot_recon_true, \n",
    "                                    performance_recon, plot_histograms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import cytokine data, integrals, projections, and MLP\n",
    "Use OT-1 datasets, it is the simplest latent space we have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptides = [\"N4\", \"Q4\", \"T4\", \"V4\", \"G4\", \"E1\", \"A2\", \"Y3\", \"A8\", \"Q7\"]\n",
    "concentrations = [\"1uM\", \"100nM\", \"10nM\", \"1nM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wt = import_WT_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_min, df_max = pd.read_pickle(os.path.join(\"data\", \"trained-networks\", \"min_max-thomasRecommendedTraining.pkl\"))\n",
    "df_min, df_max = df_min.xs(\"integral\", level=\"Feature\"), df_max.xs(\"integral\", level=\"Feature\")\n",
    "\n",
    "# Projection matrix\n",
    "P = np.load(os.path.join(\"data\", \"trained-networks\", \"mlp_input_weights-thomasRecommendedTraining.npy\")).T\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cytokines = df_min.index.get_level_values(\"Cytokine\")\n",
    "times = np.arange(0, 69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the desired cytokines, times, and T cell number\n",
    "df_wt = df_wt.unstack(\"Time\").loc[:, (slice(None), cytokines, times)].stack(\"Time\")\n",
    "\n",
    "# Rescale and project each feature\n",
    "proj_dfs = []\n",
    "feat_keys = [\"integral\", \"concentration\", \"derivative\"]\n",
    "cols = pd.Index([\"Node 1\", \"Node 2\"], name=\"Node\", copy=True)\n",
    "print(P.T)\n",
    "\n",
    "for typ in feat_keys:\n",
    "    # Rescale with the training min and max\n",
    "    if typ == \"integral\":\n",
    "        df_wt[typ] = (df_wt[typ] - df_min)/(df_max - df_min)\n",
    "    else:   # for conc and deriv, the constant offset term -df_min disappears. \n",
    "        df_wt[typ] = df_wt[typ]/(df_max - df_min)\n",
    "    df_temp = pd.DataFrame(np.dot(df_wt[typ], P.T), index=df_wt[typ].index, columns=cols)\n",
    "    proj_dfs.append(df_temp)\n",
    "df_proj = pd.concat(proj_dfs, axis=1, names=[\"Feature\"], keys=feat_keys)\n",
    "del proj_dfs, cols, feat_keys  # temporary variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select training and test data\n",
    "Use different datasets as a simple means of splitting the data. Could also use sklearn.model_selection.split_train_test, but that's not necessary: by selecting different datasets, we are sure to have similar test and train data, modulo experimental variability, since the peptide conditions are the same. \n",
    "\n",
    "Select only one T cell number for now. You could try using the same reconstruction coefficients for different T cell numbers, but it would not work as well, because the 2D manifold changes slightly depending on T cell number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove different T cell numbers\n",
    "tcellnum = \"100k\"\n",
    "df_wt = df_wt.xs(tcellnum, level=\"TCellNumber\", axis=0, drop_level=True)\n",
    "df_proj = df_proj.xs(tcellnum, level=\"TCellNumber\", axis=0, drop_level=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep multiple datasets to populate latent space better\n",
    "# Mix datasets with old and new protocols, because IL-6 is low in new ones, for instance. \n",
    "\n",
    "subset_train = [\n",
    "    \"HighMI_1-1\", \n",
    "    \"HighMI_1-3\"\n",
    "]\n",
    "df_wt_train = df_wt.loc[subset_train]\n",
    "df_proj_train = df_proj.loc[subset_train]\n",
    "\n",
    "subset_test = [\n",
    "    \"HighMI_1-2\", \n",
    "    \"HighMI_1-4\"\n",
    "]\n",
    "df_wt_test = df_wt.loc[subset_test]\n",
    "df_proj_test = df_proj.loc[subset_test]\n",
    "\n",
    "# Remove A2 and Y3 from the training\n",
    "df_wt_train = df_wt_train.drop([\"A2\", \"Y3\"], level=\"Peptide\", axis=0)\n",
    "df_proj_train = df_proj_train.drop([\"A2\", \"Y3\"], level=\"Peptide\", axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Alternative training data: use multiple experimental repeats. Convert cell to code to use\n",
    "# The resulting reconstructions are slightly less accurate, but slightly more robust. \n",
    "## Note: this is the version used for synthetic cytokine data generation from the model plus reconstruction\n",
    "subset_train = [\n",
    "    \"PeptideComparison_OT1_Timeseries_18\", \n",
    "    \"PeptideComparison_OT1_Timeseries_19\", \n",
    "    \"NewPeptideComparison_OT1_Timeseries_20\", \n",
    "    \"PeptideComparison_OT1_Timeseries_22\",\n",
    "    \"PeptideTumorComparison_OT1_Timeseries_1\" \n",
    "]\n",
    "df_wt_train = df_wt.loc[subset_train]\n",
    "df_proj_train = df_proj.loc[subset_train]\n",
    "\n",
    "subset_test = [\n",
    "    \"PeptideComparison_OT1_Timeseries_21\", \n",
    "    \"TCellNumber_OT1_Timeseries_7\",\n",
    "    \"PeptideComparison_OT1_Timeseries_23\", \n",
    "    \"CD25MutantTimeSeries_OT1_Timeseries_2\",     \n",
    "    \"Activation_Timeseries_1\", \n",
    "]\n",
    "df_wt_test = df_wt.loc[subset_test]\n",
    "df_proj_test = df_proj.loc[subset_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction of the selected feature from the projections\n",
    "\n",
    "We reconstruct only one feature (integrals, concentrations, or derivatives) at a time. Once the reconstructed cytokines are obtained, of course the other features can be recovered by differentiation or time integration. \n",
    "All possible methods are defined in ltspcyt/scripts/reconstruction.py:\n",
    "- Linear regression\n",
    "- Linear regression with quadratic terms\n",
    "- Neural network with two input variables\n",
    "- Linear regression mixed input features, some with quadratic terms. \n",
    "Here we use linear regression with quadratic terms, option \"mixedquad\", and we add $\\tanh(N_i)$ terms for saturation.\n",
    "\n",
    "To try simple linear regression, use the commented out cell instead of the one below. Note that in that case only, because of the linearity, the same reconstruction coefficients can be used for time integrals, concentrations, or derivatives alike. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the reconstruction matrix, based on reconstructing integrals\n",
    "feature = \"concentration\"\n",
    "model_type = \"mixed_quad\"\n",
    "\n",
    "modelargs = {\"which_to_square\":[0, 1]}\n",
    "\n",
    "# Add some arbitrary features. \n",
    "# Try exponentials\n",
    "norm_factors = df_proj_train[\"integral\"].mean(axis=0)\n",
    "\n",
    "\n",
    "df_proj_train2 = pd.concat([df_proj_train[\"concentration\"], np.tanh(df_proj_train[\"integral\"] / norm_factors)], \n",
    "                           keys=[\"concentration\", \"tanh_integrals\"], names=[\"Feature\"], axis=1)\n",
    "df_proj_test2 = pd.concat([df_proj_test[\"concentration\"], np.tanh(df_proj_test[\"integral\"] / norm_factors)], \n",
    "                           keys=[\"concentration\", \"tanh_integrals\"], names=[\"Feature\"], axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Convert this cell to code if you want to use linear reconstruction instead\n",
    "feature = \"concentration\"\n",
    "model_type = \"linear\"\n",
    "\n",
    "modelargs = dict()\n",
    "\n",
    "df_proj_train2 = df_proj_train.xs(feature, level=\"Feature\", drop_level=False, axis=1)\n",
    "df_proj_test2 = df_proj_test.xs(feature, level=\"Feature\", drop_level=False, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe, score = train_reconstruction(df_proj_train2, df_wt_train, feature=feature, \n",
    "                                   method=model_type, model_args=modelargs, do_scale_out=False)\n",
    "print(\"R^2 training score:\", score)\n",
    "print(\"Regression coefficients (Q matrix):\")\n",
    "print(pipe[model_type].regressor_.Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct both the test and training data sets, for the selected feature (pipeline does not work for others)\n",
    "# Don't need the inverse_transform, because when mlpreg.predict is called, the inverse transform is applied on the prediction of the regressor. \n",
    "# These wrappers work well! no need to worry about all the steps\n",
    "# Danger: forget what's happening under the hood.\n",
    "\n",
    "columns2 = pd.MultiIndex.from_product([[feature], df_wt_train[feature].columns], names=df_wt_train.columns.names)\n",
    "\n",
    "df_recon_train = pd.DataFrame(pipe.predict(df_proj_train2), index=df_wt_train.index, \n",
    "                              columns=columns2)\n",
    "df_recon_test = pd.DataFrame(pipe.predict(df_proj_test2), index=df_wt_test.index, \n",
    "                             columns=columns2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save reconstruction results"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Convert cell to code to save results\n",
    "# Save the results: pipeline, processed latent space used as input and reconstruction\n",
    "recontype = \"nonlinear\" if model_type == \"mixed_quad\" else model_type\n",
    "\n",
    "fnames = os.path.join(\"results\", \"reconstruction\", \"df_{}_\" + recontype + \"_HighMI_1.hdf\")\n",
    "with open(os.path.join(\"results\", \"reconstruction\", \"quadratic_tanh_pipeline_HighMI_1.pkl\"), \"wb\") as fi:\n",
    "    pickle.dump(pipe, fi)\n",
    "\n",
    "if recontype == \"nonlinear\":\n",
    "    norm_factors.to_hdf(os.path.join(\"results\", \"reconstruction\", \n",
    "        \"tanh_norm_factors_integrals_HighMI_1.hdf\"), key=\"df\")\n",
    "\n",
    "df_recon_train.to_hdf(fnames.format(\"recon\"), key=\"train\", mode=\"w\")\n",
    "df_recon_test.to_hdf(fnames.format(\"recon\"), key=\"test\", mode=\"a\")\n",
    "\n",
    "df_proj_train.to_hdf(fnames.format(\"proj\"), key=\"train\", mode=\"w\")\n",
    "df_proj_test.to_hdf(fnames.format(\"proj\"), key=\"test\", mode=\"a\")\n",
    "\n",
    "df_wt_train.to_hdf(fnames.format(\"wt\"), key=\"train\", mode=\"w\")\n",
    "df_wt_test.to_hdf(fnames.format(\"wt\"), key=\"test\", mode=\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the reconstruction and data for test replicates\n",
    "Plot per cytokine, for all datasets, to infer general trends that we can then correct manually for each cytokine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per experiment\n",
    "figlist = plot_recon_true(df_wt_test, df_recon_test, feature=feature, sharey=True)\n",
    "# If one wants to select only a subset of the data\n",
    "#figlist = plot_recon_true(df_wt_test.loc[(slice(None), [\"N4\", \"T4\"]), :], \n",
    "#                          df_recon_test.loc[(slice(None), [\"N4\", \"T4\"]), :], \n",
    "#                          feature=feature, sharey=True)\n",
    "for exp in figlist.keys():\n",
    "    legend = figlist[exp].axes[-1].get_legend()\n",
    "    figlist[exp].set_size_inches(9, 6)\n",
    "    #figlist[exp].savefig(os.path.join(\"figures\", \"reconstruction\", \n",
    "    #    \"cyto_reconstruction_{}-test_{}.pdf\".format(exp, recontype)), format=\"pdf\", \n",
    "    #        transparent=True, bbox_extra_artists=(legend,), bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantification of the reconstruction performance\n",
    "Histogram of residuals and residuals over time. \n",
    "\n",
    "Note that the R2 score computed by sklearn is slightly different, because it takes the uniform average of the R2 score of each cytokine separately. If $X$ is the true data (shape $N_{samp} \\times {N_{dim}}$) and $\\hat{X}$ is the reconstruction:\n",
    "\n",
    "$$ R^2_{sklearn} = \\frac{1}{N_{dim}}\\sum_{j=1}^{N_{dim}} \\left[ 1 - \\frac{\\sum_{i} (X_{ij} - \\hat{X}_{ij})^2}{\\sum_{i'}(X_{i'j} - \\langle X_{j} \\rangle)^2}  \\right]$$\n",
    "\n",
    "Here, we treat the five cytokines as 5 components of a 5D vector and sum the squared residuals in the five dimensions (i.e. compute the L2 norm of the difference vector) into a single R2 score. \n",
    "\n",
    "$$ R^2_{vector} = 1 -  \\frac{\\sum_{i, j} (X_{ij} - \\hat{X}_{ij})^2}{\\sum_{i'j} (X_{i'j} - \\langle X_{j} \\rangle)^2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the performance of the reconstruction, per dataset\n",
    "perform_train = performance_recon(df_wt_train, df_recon_train, toplevel=\"Data\", feature=feature)\n",
    "perform_test = performance_recon(df_wt_test, df_recon_test, toplevel=\"Data\", feature=feature)\n",
    "#perform_train_conc = performance_recon(df_wt_train, df_recon_train, toplevel=\"Data\", feature=\"concentration\")\n",
    "#perform_test_conc = performance_recon(df_wt_test, df_recon_test, toplevel=\"Data\", feature=\"concentration\")\n",
    "\n",
    "# Plot the histograms and print the results\n",
    "print(\"------ Performance on TRAIN datasets ------\")\n",
    "print(\"-- {} --\".format(feature))\n",
    "print(\"R2 coefficient (score):\", perform_train[-1])\n",
    "print(\"Residuals per dataset: \\n\", perform_train[0])\n",
    "fig, axes = plot_histograms(perform_train[1], perform_train[2])\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(\"------ Performance on TEST datasets ------\")\n",
    "print(\"-- {} --\".format(feature))\n",
    "print(\"R2 coefficient (score):\", perform_test[-1])\n",
    "print(\"Residuals per dataset per point: \\n\", perform_test[0])\n",
    "fig, axes = plot_histograms(perform_test[1], perform_test[2])\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot residuals\n",
    "palette_backup = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "peptides_backup_short = [\"N4\", \"Q4\", \"T4\", \"V4\", \"A2\"]\n",
    "\n",
    "def plot_residuals_percyto(df_res, feature=\"integral\", toplevel=\"Data\", datatype=\"relative\",\n",
    "    sharey=True, palette=palette_backup, pept=peptides_backup_short, y_lims=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        df_res (pd.DataFrame): dataframe containing relative residuals\n",
    "        feature (str): the feature to compare (\"integral\", \"concentration\", \"derivative\")\n",
    "        toplevel (str): the first index level, one plot per entry\n",
    "        datatype (str): \"relative\" or \"absolute\"\n",
    "        sharey (bool): whether or not the y axis on each row should be shared\n",
    "            True by default, allows to see if somne cytokines weigh less in the reconstruction.\n",
    "        palette (list): list of colors, at least as long as pept\n",
    "        pept (list): list of peptides\n",
    "        y_lims (pd.DataFrame): dataframe of maxes\n",
    "    \"\"\"\n",
    "    # Slice for the desired feature\n",
    "    df = df_res.xs(feature, level=\"Feature\", axis=1, drop_level=True)\n",
    "\n",
    "    # Plot the result\n",
    "    # Rows are for cytokines, columns for peptides\n",
    "    # One panel per dataset\n",
    "    figlist = {}\n",
    "    for cyt in df.columns.get_level_values(\"Cytokine\").unique():\n",
    "        # Extract labels\n",
    "        cols = df.index.get_level_values(\"Peptide\").unique()\n",
    "        cols = [p for p in pept if p in cols]  # Use the right order\n",
    "        try:\n",
    "            rows = df.index.get_level_values(toplevel).unique()\n",
    "        except KeyError:\n",
    "            rows = df.columns.get_level_values(\"Node\").unique()\n",
    "            print(\"Reconstructing latent space\")\n",
    "        # Sort the concentrations\n",
    "        concs_num = sort_SI_column(df.index.get_level_values(\"Concentration\").unique(), \"M\")\n",
    "        concs = np.asarray(df.index.get_level_values(\"Concentration\").unique())[np.argsort(concs_num)]\n",
    "        # Prepare colors and sizes\n",
    "        colors = {cols[i]:palette[i] for i in range(len(cols))}\n",
    "        sizes = {concs[i]:1 + i for i in range(len(concs))}\n",
    "        fig, axes = plt.subplots(len(rows), len(cols), sharex=False, sharey=sharey)\n",
    "        fig.set_size_inches(3*len(cols), 3*len(rows))\n",
    "        times = df.index.get_level_values(\"Time\").unique()\n",
    "        times = [float(t) for t in times]\n",
    "        for i, xp in enumerate(rows):\n",
    "            for j, pep in enumerate(cols):\n",
    "                for k in concs:\n",
    "                    try:\n",
    "                        li1, = axes[i, j].plot(times, df.loc[(xp, pep, k), cyt],\n",
    "                                    color=colors[pep], lw=sizes[k], ls=\"-\")\n",
    "                        li2 = axes[i, j].axhline(0, color=\"k\", ls=\"--\", lw=1.)\n",
    "                    except KeyError:  # This combination dos not exist\n",
    "                        continue\n",
    "                # Some labeling\n",
    "                if j == 0:\n",
    "                    units = \"\" if datatype == \"absolute\" else \" [%]\"\n",
    "                    axes[i, j].set_ylabel(xp[:-20] + \"\\n\" + \"Residuals\" + units)\n",
    "                    if y_lims is not None:\n",
    "                        axes[i, j].set_ylim(-y_lims.loc[xp, (feature, cyt)], \n",
    "                                              y_lims.loc[xp, (feature, cyt)])\n",
    "                if i == len(rows) - 1:\n",
    "                    axes[i, j].set_xlabel(\"Time\")\n",
    "                elif i == 0:\n",
    "                    axes[i, j].set_title(pep)\n",
    "        # Save the figure afterwards, with a title\n",
    "        fig.suptitle(cyt)\n",
    "        figlist[cyt] = fig\n",
    "    return figlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals (negative if the reconstruction is smaller than the true value)\n",
    "df_resids_test = df_recon_test - df_wt_test\n",
    "df_resids_train = df_recon_train - df_wt_train\n",
    "\n",
    "# Find max of each cytokine across all peptides, etc. so it's the min, max of the plots\n",
    "ylims_train = df_wt_train.groupby(\"Data\", axis=0).max()\n",
    "ylims_test = df_wt_test.groupby(\"Data\", axis=0).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figlist = plot_residuals_percyto(df_resids_test, feature=feature, sharey=True, \n",
    "                                 datatype=\"absolute\", y_lims=ylims_test)\n",
    "for cyt in figlist.keys():\n",
    "    legend = figlist[cyt].axes[-1].get_legend()\n",
    "    #figlist[cyt].savefig(os.path.join(\"figures\", \"reconstruction\", \n",
    "    #        \"cyto_reconstruction_HighMI_1-test_\" + cyt + \"_\" + recontype + \".pdf\"), \n",
    "    #        format=\"pdf\", transparent=True, bbox_extra_artists=(legend,), bbox_inches='tight')\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
