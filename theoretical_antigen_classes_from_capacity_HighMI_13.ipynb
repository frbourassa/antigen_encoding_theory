{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theoretical antigen classes from channel capacity results\n",
    "\n",
    "To run this notebook, you need:\n",
    "- To have run the notebook `compute_channel_capacity_HighMI_13.ipynb` and saved its outputs (by uncommenting the lines that save files), which are saved in folders `results/fits/` and `results/capacity/`.\n",
    "- To have run the script `more_main_scripts/chancap_interpol_bootstrap.py`. \n",
    "- To have run the notebook `reconstruct_cytokines_fromLSdata.ipynb` and saved its outputs in the folder `results/reconstruction`, by default training on the dataset HighMI_1 (result files `quadratic_tanh_pipeline_HighMI_1.pkl` and `\"tanh_norm_factors_integrals_HighMI_1.hdf\"`)\n",
    "- Raw cytokine time series in `data/final/`, in particular the corrected dataset `\"cytokineConcentrationPickleFile-20210619-HighMI_13-final-corrected.pkl\"` (corrected by the channel capacity notebook above), to recover the absolute scale of cytokine concentrations after reconstruction. \n",
    "- The input weights of a neural network and the min and max cytokine concentrations used to scale the data, in `data/trained-networks`. \n",
    "- Table of OT-1 antigens' EC$_{50}$s, values from the literature and from our own measurements, in the JSON file `data/misc/potencies_df_2021.json`. Also, for plotting aesthetics, tick parameters saved in JSON files in this folder. \n",
    "\n",
    "The files mentioned above are available in the data repository hosted online. \n",
    "\n",
    "## Procedure\n",
    "Based on the channel capacity $C$ found, there are $2^{C}$ peptide quality categories that our cytokine latent space and ballistic parameter space can tell apart \"perfectly\". We can derive the EC$_{50}$ values and hence the model parameter conditional distributions to which those $2^C$ categories correspond. The idea is to use the optimal antigen probability distribution $p_Q$ found by the Blahut-Arimoto algorithm, and pick EC$_{50}$ values that correspond to evenly spaced values of the cumulative distribution function, $CDF(q) = \\sum_{q' \\leq q} p_Q(q')$. As we will see, the model parameter distributions thus selected give model trajectories that optimally fill the latent space, hence they optimize antigen encoding. \n",
    "\n",
    "A difficulty arises. Multivariate normal distributions were only obtained for the channel capacity calculation on three parameters, $a_0$, $\\tau_0$ and $\\theta$. We thus miss parameters $v_2$, $\\alpha$, $\\beta$, and the $v_2 / v_1$ slope to completely specify a trajectory of the force model with matching. We solve this problem by linearly interpolating between the $v_2$ values of the two experimental peptides closest to the desired theoretical peptide. We use the $v_2 / v_1$ slope from the HighMI_1 experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import interpolate\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as clr\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import json, pickle\n",
    "import os\n",
    "\n",
    "from ltspcyt.scripts.reconstruction import QuadraticRegression, compute_latent_curves\n",
    "from utils.recon_scaling import scale_back, import_folder_naive_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Label sizes for Science format (figure width 2.25 inches or 4.75 inches)\n",
    "# Squeezing three subplots in a row: 4.75/3 = 1.583333\n",
    "sns.reset_orig()\n",
    "plt.rcParams[\"figure.figsize\"] = (1.55, 1.65)\n",
    "plt.rcParams[\"font.size\"] = 8\n",
    "plt.rcParams[\"axes.labelsize\"] = 7\n",
    "plt.rcParams[\"legend.fontsize\"] = 7\n",
    "plt.rcParams[\"xtick.labelsize\"] = 6\n",
    "plt.rcParams[\"ytick.labelsize\"] = 6\n",
    "plt.rcParams[\"xtick.major.pad\"] = 2.  # distance to major tick label in points\n",
    "plt.rcParams[\"xtick.minor.pad\"] = 2.\n",
    "plt.rcParams[\"axes.labelpad\"] = 1.\n",
    "plt.rcParams[\"axes.linewidth\"] = 0.8\n",
    "plt.rcParams[\"axes.spines.top\"] = False\n",
    "plt.rcParams[\"axes.spines.right\"] = False\n",
    "\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 250 # default for me was 75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import previous results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use parameters and multivariate distributions without bootstrap perturbations, because we did not\n",
    "# save those for all bootstrap replicates and anyways the unperturbed ones should be approx. the average, \n",
    "# or at least representative of the parameters and trajectories of theoretical peptide categories. \n",
    "df_params = pd.read_hdf(os.path.join(\"results\", \"fits\", \"df_params_Sigmoid_freealpha_HighMI_13.hdf\"))\n",
    "interpolated_means = np.load(os.path.join(\"results\", \"capacity\", \"meanmats_25inputs_HighMI_13.npy\"))\n",
    "interpolated_covmats = np.load(os.path.join(\"results\", \"capacity\", \"covmats_25inputs_HighMI_13.npy\"))\n",
    "\n",
    "# Here, for the capacity itself, we can use the bootstrap result\n",
    "with open(os.path.join(\"results\", \"capacity\", \"capacity_bootstrap_results_HighMI_13.json\"), \"r\") as h:\n",
    "    chancap_run_results = json.load(h)\n",
    "print(chancap_run_results.keys())\n",
    "\n",
    "# Approximately the ratio used for HighMI_13, based on HighMI_1.\n",
    "v2_v1_ratio = 7.8\n",
    "\n",
    "df_potencies = pd.read_json(os.path.join(\"data\", \"misc\", \"potencies_df_2021.json\"))\n",
    "ser_log10ec50s = np.log10(df_potencies).mean(axis=1)\n",
    "ser_log10ec50s.index.name = \"Peptide\"\n",
    "# Only keep peptides for which we have parameter values\n",
    "ser_log10ec50s = ser_log10ec50s.loc[df_params.index.get_level_values(\"Peptide\").unique()]\n",
    "print(ser_log10ec50s)\n",
    "\n",
    "# Other parameters that we will need: take the mean for each peptide. \n",
    "ser_means_pars = {\n",
    "    \"v1\": df_params[\"v1\"].groupby(\"Peptide\").mean(), \n",
    "    \"alpha\": df_params[\"alpha\"].groupby(\"Peptide\").mean(), \n",
    "    \"beta\": df_params[\"beta\"].groupby(\"Peptide\").mean()\n",
    "}\n",
    "ser_variances_pars = {\n",
    "    \"v1\": df_params[\"v1\"].groupby(\"Peptide\").var(), \n",
    "    \"alpha\": df_params[\"alpha\"].groupby(\"Peptide\").var(), \n",
    "    \"beta\": df_params[\"beta\"].groupby(\"Peptide\").var()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate ballistic parameter samples for each theoretical peptide\n",
    "1. Identify the theoretical peptides: one at each endpoint of the discretized axis of $\\log_{10} \\mathrm{EC}_{50}$, and one at each of $n_{\\mathrm{cat}} = \\log_2{C} - 2$ points evenly spaced in the values of the cumulative mass function after removing the edge probabilities (e.g. at 0.25, 0.5, 0.75 total probability if there are $5-2 = 3$ categories). Otherwise the 1st-2nd and penultimate-last pairs are too close to each other. This is an effect o discretization. \n",
    "\n",
    "2. Define a function that, for an arbitrary $\\log_{10} \\mathrm{EC}_{50}$, interpolates between the values and variances of $v_t$ of the two nearest peptides on the quality axis. Find the average and variance of $v_t$ for each theoretical peptide\n",
    "\n",
    "3. Generate the mean trajectory for each theoretical peptide. \n",
    "\n",
    "4. Generate a bunch of randomly sampled trajectories around the mean for each peptide, using the $(F, t_0, \\theta)$ multivariate normal distribution and the interpolated variance of $v_t$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Theoretical antigen classes' EC$_{50}$s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_indices_uniform_cumulative(nsep, pmf):\n",
    "    \"\"\"Given a probability mass function in the array pmf, find the indices of the \n",
    "    locations where evenly spaced cumulative mass function values, after removing the edges, fall. \n",
    "    The first and last nsep are 0 and len(pmf)-1\n",
    "    \"\"\"\n",
    "    # First separator: at 0, last separator: at the end\n",
    "    indices = np.zeros(nsep, dtype=int)\n",
    "    indices[-1] = len(pmf) - 1\n",
    "    \n",
    "    if nsep <= 2:\n",
    "        return indices\n",
    "    \n",
    "    # Inner separators: use numpy's searchsorted function\n",
    "    # Here, we do not consider the probability associated to the first and last bin\n",
    "    # So we look for bin separators at binwidth past pmf[0] or binwidth before pmf[-1]\n",
    "    # With the binwidth disregarding the edge probabilities as well. \n",
    "    inner_prob = np.sum(pmf[1:-1])\n",
    "    binwidth = inner_prob / (nsep - 1)\n",
    "    binseps = np.linspace(pmf[0]+binwidth, 1.0 - binwidth - pmf[-1], nsep - 2)\n",
    "    indices[1:-1] = np.searchsorted(np.cumsum(pmf), binseps)\n",
    "    \n",
    "    # The following should not happen if indeed we have nsep categories. \n",
    "    if np.any(indices[1:] == indices[:-1]):\n",
    "        print(indices)\n",
    "        raise ValueError(\"Found two categories in the same discrete input value\")\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find the number of categories based on the capacity\n",
    "n_categories = int(round(2**chancap_run_results[\"average_capacity_bits\"]))\n",
    "print(n_categories)\n",
    "\n",
    "# Find the indices of theoretical classes\n",
    "theo_peptides_indices = find_indices_uniform_cumulative(n_categories, chancap_run_results[\"optimal_distribution\"])\n",
    "print(theo_peptides_indices)\n",
    "\n",
    "theo_peptides_log10ec50s = np.asarray(chancap_run_results[\"input_values\"])[theo_peptides_indices]\n",
    "theo_peptides_log10ec50s[0] = 0.0  # First should be N4, not the midpoint in the 1st category\n",
    "# And last should be E1: last midpoint plus half width (which is the first midpoint)\n",
    "theo_peptides_log10ec50s[-1] = chancap_run_results[\"input_values\"][-1] + chancap_run_results[\"input_values\"][0] - 1e-15\n",
    "print(np.around(theo_peptides_log10ec50s, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Interpolation between nearest peptides for $v_1$, $\\alpha$, $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to interpolate any parameter between nearest antigens\n",
    "def interpolate_nearest_peptides(logec50, pep_logec50s, ser_values):\n",
    "    \"\"\" Given an arbitrary log_10 EC_50, a list of peptide log_10 EC_50s, and a \n",
    "    value of the quantity to interpolate for each peptide label, find the two peptides\n",
    "    closest to the desired EC_50 and interpolate linearly between their values. \"\"\"\n",
    "    # Find the peptide below and the peptide above\n",
    "    sorted_ec50s = pep_logec50s.sort_values()\n",
    "    ec50_index_above = np.searchsorted(sorted_ec50s, logec50, side=\"left\")\n",
    "    try:\n",
    "        ec50_above = sorted_ec50s.iloc[ec50_index_above]\n",
    "    except IndexError:\n",
    "        raise ValueError(\"We are above the interpolation range\")\n",
    "    else:\n",
    "        pep_above = sorted_ec50s.index.to_series().iloc[ec50_index_above]\n",
    "    \n",
    "    try:\n",
    "        ec50_below = sorted_ec50s.iloc[ec50_index_above-1]\n",
    "    except IndexError:\n",
    "        raise ValueError(\"We are below the interpolation range\")\n",
    "    else:\n",
    "        pep_below = sorted_ec50s.index.to_series().iloc[ec50_index_above-1]\n",
    "    \n",
    "    # Find the parameter values below and above\n",
    "    try:\n",
    "        value_below = ser_values[pep_below]\n",
    "        value_above = ser_values[pep_above]\n",
    "    except KeyError as e:\n",
    "        print(\"Peptide {} not available; check consistency of EC50 and parameter tables.\")\n",
    "        raise e\n",
    "    \n",
    "    # Interpolate linearly\n",
    "    value_inter = (logec50 - ec50_below) / (ec50_above - ec50_below) * (value_above - value_below) + value_below\n",
    "    return value_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate each parameter\n",
    "theo_peptides_par_means = {\n",
    "    \"v1\": np.asarray(list(map(lambda x: interpolate_nearest_peptides(x, ser_log10ec50s, ser_means_pars[\"v1\"]), \n",
    "                             theo_peptides_log10ec50s))), \n",
    "    \"alpha\": np.asarray(list(map(lambda x: interpolate_nearest_peptides(x, ser_log10ec50s, ser_means_pars[\"alpha\"]), \n",
    "                             theo_peptides_log10ec50s))),\n",
    "    \"beta\": np.asarray(list(map(lambda x: interpolate_nearest_peptides(x, ser_log10ec50s, ser_means_pars[\"beta\"]), \n",
    "                             theo_peptides_log10ec50s)))\n",
    "}\n",
    "theo_peptides_par_varis = {\n",
    "    \"v1\": np.asarray(list(map(lambda x: interpolate_nearest_peptides(x, ser_log10ec50s, ser_variances_pars[\"v1\"]), \n",
    "                             theo_peptides_log10ec50s))), \n",
    "    \"alpha\": np.asarray(list(map(lambda x: interpolate_nearest_peptides(x, ser_log10ec50s, ser_variances_pars[\"alpha\"]), \n",
    "                             theo_peptides_log10ec50s))),\n",
    "    \"beta\": np.asarray(list(map(lambda x: interpolate_nearest_peptides(x, ser_log10ec50s, ser_variances_pars[\"beta\"]), \n",
    "                             theo_peptides_log10ec50s)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to check that the linear interpolation is OK. \n",
    "fig, ax = plt.subplots(1, 2)\n",
    "pch = \"alpha\"  # Parameter choice for this interpolation check plot\n",
    "sorted_peptides = ser_log10ec50s.sort_values().index\n",
    "ax[0].plot(ser_log10ec50s[sorted_peptides], ser_means_pars[pch][sorted_peptides], marker=\"o\", label=\"Peptides\", ms=4)\n",
    "ax[0].plot(theo_peptides_log10ec50s, theo_peptides_par_means[pch], \"co\", label=\"Interpolated\", ms=4)\n",
    "ax[0].set(xlabel=r\"$\\log_{10}$EC$_{50}$\", ylabel=r\"$\\langle {} \\rangle$\".format(pch))\n",
    "ax[0].vlines(theo_peptides_log10ec50s, ymin=0, ymax=theo_peptides_par_means[pch], linestyle=\"--\", color=\"grey\", lw=0.8)\n",
    "\n",
    "ax[1].plot(ser_log10ec50s[sorted_peptides], ser_variances_pars[pch][sorted_peptides], marker=\"o\", label=\"Peptides\", ms=4)\n",
    "ax[1].plot(theo_peptides_log10ec50s, theo_peptides_par_varis[pch], \"co\", label=\"Interpolated\", ms=4)\n",
    "ax[1].set(xlabel=r\"$\\log_{10}$EC$_{50}$\", ylabel=r\"Var$[{}]$\".format(pch))\n",
    "ax[1].vlines(theo_peptides_log10ec50s, ymin=0, ymax=theo_peptides_par_varis[pch], linestyle=\"--\", color=\"grey\", lw=0.8)\n",
    "ax[1].legend(fontsize=6)\n",
    "fig.set_size_inches(3., 1.5)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Compute the mean parameter values of each theoretical peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_theo_meanparams = pd.DataFrame(np.zeros([n_categories, 7]), \n",
    "                        index=pd.Index(range(n_categories), name=\"TheoreticalPeptide\"), \n",
    "                        columns=pd.Index([\"a0\", \"tau0\", \"theta\", \"v1\", \"alpha\", \"beta\", \"log10ec50\"], \n",
    "                                            name=\"Parameter\"))\n",
    "df_theo_meanparams.iloc[:, :3] = interpolated_means[theo_peptides_indices]\n",
    "\n",
    "for i, pch in zip((3, 4, 5), (\"v1\", \"alpha\", \"beta\")):\n",
    "    df_theo_meanparams.iloc[:, i] = theo_peptides_par_means[pch]\n",
    "\n",
    "df_theo_meanparams.iloc[:, 6] = theo_peptides_log10ec50s\n",
    "print(df_theo_meanparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Sample a bunch of parameter values around the mean of each theoretical peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rndgen = np.random.RandomState(seed=53739)\n",
    "nsamples = 32\n",
    "df_theo_samples = pd.DataFrame(np.zeros([nsamples*n_categories, 7]), \n",
    "                        index=pd.MultiIndex.from_product([range(n_categories), range(nsamples)], \n",
    "                            names=[\"TheoreticalPeptide\", \"Sample\"]), \n",
    "                        columns=df_theo_meanparams.columns)\n",
    "\n",
    "for i in range(n_categories):\n",
    "    # Generate nsamples parameter samples for each peptide\n",
    "    df_theo_samples.loc[i].iloc[:, :3] = np.clip(rndgen.multivariate_normal(\n",
    "        interpolated_means[theo_peptides_indices[i]], \n",
    "        interpolated_covmats[theo_peptides_indices[i]], nsamples), \n",
    "        a_min=[0.0, 0.0, -np.pi], a_max=None)\n",
    "    \n",
    "    for j, pch in zip((3, 4, 5), (\"v1\", \"alpha\", \"beta\")):\n",
    "        df_theo_samples.loc[i].iloc[:, j] = np.clip(rndgen.normal(\n",
    "            theo_peptides_par_means[pch][i], theo_peptides_par_varis[pch][i], nsamples), a_min=0.02, a_max=None)\n",
    "    \n",
    "    df_theo_samples.loc[i].iloc[:, 6] = theo_peptides_log10ec50s[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute trajectories for the sampled parameter values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import equations of the constant force model with matching\n",
    "from ltspcyt.scripts.sigmoid_ballistic import ballistic_sigmoid_freealpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute model trajectories for theoretical antigen classes\n",
    "times = np.arange(0, 73)\n",
    "tscale = 20.0\n",
    "\n",
    "# Trajectories for parameter values sampled in each theoretical antigen class distribution\n",
    "df_traj = pd.DataFrame(np.zeros([df_theo_samples.shape[0], 2*len(times)]), \n",
    "                      index=df_theo_samples.index, \n",
    "                      columns=pd.MultiIndex.from_product([[\"Node 1\", \"Node 2\"], times], names=[\"Node\", \"Time\"]))\n",
    "\n",
    "for key in df_traj.index:\n",
    "    n1, n2 = ballistic_sigmoid_freealpha(times / tscale, *df_theo_samples.loc[key].iloc[:6], v2v1_ratio=v2_v1_ratio)\n",
    "    # Transpose the df before slicing, because assigning one element per column is super slow. \n",
    "    # So assign to one column, the \"key\" column. Makes building the df a lot faster. \n",
    "    df_traj.T.loc[\"Node 1\", key] = n1\n",
    "    df_traj.T.loc[\"Node 2\", key] = n2\n",
    "\n",
    "    \n",
    "# Trajectories for average parameter values of each theoretical antigen class\n",
    "df_traj_mean = pd.DataFrame(np.zeros([df_theo_meanparams.shape[0], 2*len(times)]), \n",
    "                      index=df_theo_meanparams.index, \n",
    "                      columns=pd.MultiIndex.from_product([[\"Node 1\", \"Node 2\"], times], names=[\"Node\", \"Time\"]))\n",
    "\n",
    "for ky in df_traj_mean.index:\n",
    "    n1, n2 = ballistic_sigmoid_freealpha(times / tscale, *df_theo_meanparams.loc[ky].iloc[:6], v2v1_ratio=v2_v1_ratio)\n",
    "    # Transpose the df before slicing, because assigning one element per column is super slow. \n",
    "    # So assign to one column, the \"key\" column. Makes building the df a lot faster. \n",
    "    df_traj_mean.T.loc[(\"Node 1\",), ky] = n1\n",
    "    df_traj_mean.T.loc[(\"Node 2\",), ky] = n2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Convert cell to code to export the theoretical antigen EC50s, latent space trajectories, averages and samples\n",
    "folder = os.path.join(\"results\", \"capacity\")\n",
    "np.save(os.path.join(folder, \"theo_antigen_classes_log10ec50s_highmi13.npy\"), theo_peptides_log10ec50s)\n",
    "np.save(os.path.join(folder, \"theo_antigen_classes_indices_highmi13.npy\"), theo_peptides_indices)\n",
    "df_traj.to_hdf(os.path.join(folder, \"chancap_theo_antigen_trajectories_highmi13.hdf\"), key=\"samples\", mode=\"w\")\n",
    "df_traj_mean.to_hdf(os.path.join(folder, \"chancap_theo_antigen_trajectories_highmi13.hdf\"), key=\"means\", mode=\"a\")\n",
    "df_theo_meanparams.to_hdf(os.path.join(folder, \"chancap_theo_antigen_trajectories_highmi13.hdf\"), key=\"meanparams\", mode=\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute $N1$ and $N2$ at a chosen time\n",
    "The goal is to show a parameterized line $N_1(EC50)$, $N_2(EC50)$ at constant $t_{choice}$ on the latent space trajectories of theoretical antigen classes. Then, on a separate plot, we will show the values of $N_1$ and $N_2$ on that curve as a function of EC$_{50}$ explicitly, to reveal the monotonicity of $N_1$ and the non-monotonicity of $N_2$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute N1 and N2 at chosen time t for each set of parameters (average)\n",
    "tchoice = 36\n",
    "\n",
    "df_n1n2_ec50 = pd.DataFrame(np.zeros([interpolated_means.shape[0], 3]), \n",
    "            index=pd.Index(range(chancap_run_results[\"n_inputs\"]), name=\"Antigen_class\"), \n",
    "            columns=pd.Index([\"Latent Space 1\", \"Latent Space 2\", \"log10ec50\"], name=\"Node\"))\n",
    "for k in df_n1n2_ec50.index:\n",
    "    logec50 = chancap_run_results[\"input_values\"][k]\n",
    "    v1 = interpolate_nearest_peptides(logec50, ser_log10ec50s, ser_means_pars[\"v1\"])\n",
    "    alpha = interpolate_nearest_peptides(logec50, ser_log10ec50s, ser_means_pars[\"alpha\"])\n",
    "    beta = interpolate_nearest_peptides(logec50, ser_log10ec50s, ser_means_pars[\"beta\"])\n",
    "    n1, n2 = ballistic_sigmoid_freealpha(np.asarray([tchoice/20.]), *interpolated_means[k], v1, alpha, beta, v2v1_ratio=v2_v1_ratio)\n",
    "    df_n1n2_ec50.iloc[k, :2] = [n1, n2]\n",
    "    df_n1n2_ec50.iloc[k, 2] = logec50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main figure 3, panels C+D: plot the theoretical antigen classes determination and trajectories\n",
    "C: Optimal probability mass function for antigen categories, cumulative mass function, and latent space trajectories sampled from each category. \n",
    "\n",
    "D: $N_1$ and $N_2$ as a function of EC$_{50}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tools\n",
    "# Logarithmic minor ticks (we plotted the real log so need to put log ticks manually)\n",
    "# Find the linear scale limiting ticks\n",
    "def compute_log_minor_ticks(loglims, stp=2, base=10.0):\n",
    "    smallest_major = int(np.floor(loglims[0]))\n",
    "    largest_major = int(np.ceil(loglims[1]))\n",
    "    n_decades = largest_major - smallest_major\n",
    "\n",
    "    # Generate linear ranges with the exponents found\n",
    "    tiles = []\n",
    "    for i in range(n_decades):\n",
    "        tiles.append(np.arange(stp*base**(smallest_major+i), \n",
    "                    base**(smallest_major+i+1), stp*base**(smallest_major+i)))\n",
    "    minorticks = np.concatenate(tiles, axis=0)\n",
    "    minorticks = np.log(minorticks) / np.log(base)\n",
    "    minorticks = minorticks[(minorticks > loglims[0]) * (minorticks < loglims[1])]\n",
    "    return minorticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract some values from the channel capacity results\n",
    "sampled_logec50 = chancap_run_results[\"input_values\"]\n",
    "optim_input_distrib = chancap_run_results[\"optimal_distribution\"]\n",
    "capacity_bits = chancap_run_results[\"average_capacity_bits\"]\n",
    "reltol = chancap_run_results[\"relative_tolerance\"]\n",
    "abserrror_cap = np.sqrt(chancap_run_results[\"variance_capacity_bits\"])\n",
    "\n",
    "# Cumulate starting at E1, so reverse the ec50 axis. \n",
    "pmf = chancap_run_results[\"optimal_distribution\"][::-1]\n",
    "nsep = int(round(2**chancap_run_results[\"average_capacity_bits\"]))\n",
    "indices = np.zeros(nsep, dtype=int)\n",
    "indices[-1] = len(pmf) - 1\n",
    "\n",
    "cumul_prob = np.cumsum(pmf)\n",
    "inner_prob = np.sum(pmf[1:-1])\n",
    "binwidth = inner_prob / (nsep - 1)\n",
    "binseps = np.linspace(pmf[0]+binwidth, 1.0 - binwidth - pmf[-1], nsep - 2)\n",
    "indices[1:-1] = np.searchsorted(cumul_prob, binseps)\n",
    "indices = theo_peptides_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color palettes for theoretical antigen classes and LS nodes\n",
    "#For theoretical peptides\n",
    "all_theo_antigen_colors = sns.color_palette(\"deep\", 10)\n",
    "theoretical_antigen_colors = [all_theo_antigen_colors[0],all_theo_antigen_colors[6]]+all_theo_antigen_colors[1:5]\n",
    "theoretical_antigen_colors = [sns.set_hls_values(a, s=0.4, l=0.6) for a in theoretical_antigen_colors]\n",
    "theoretical_antigen_colors[-1] = (0, 0, 0, 1)  # Make the null peptide black. \n",
    "\n",
    "colors = sns.color_palette(\"deep\", n_categories)\n",
    "colors = [sns.set_hls_values(a, s=0.4, l=0.6) for a in colors]\n",
    "colors[-1] = (0, 0, 0, 1)  # Make the null (last) peptide black. \n",
    "#Remove next line if you want to revert to old color scheme\n",
    "colors = theoretical_antigen_colors.copy()\n",
    "\n",
    "colors_samples = [sns.set_hls_values(a, l=0.8) for a in theoretical_antigen_colors]\n",
    "#Remove next line if you want to revert to old color scheme\n",
    "colors_samples = theoretical_antigen_colors.copy()\n",
    "colors_samples[-1] = (0.5, 0.5, 0.5, 0.8)\n",
    "\n",
    "\n",
    "colors_dict = {df_traj_mean.index[i]:colors[i] for i in range(n_categories)}\n",
    "colors_samples_dict = {df_traj_mean.index[i]:colors_samples[i] for i in range(n_categories)}\n",
    "\n",
    "# Colors for Nodes 1+2, Node 1, Node 2\n",
    "latent_colors = [list(clr.to_rgba(a)) for a in [\"crimson\", \"goldenrod\", \"maroon\"]]  # both, node 1, node 2\n",
    "latent_colors[1] = sns.set_hls_values(color=latent_colors[1], h=None, l=0.6, s=None)  # making goldenrod lighter\n",
    "latent_colors[0] = sns.set_hls_values(color=latent_colors[0], h=None, l=0.5, s=None)  # make crimson lighter\n",
    "nodePalette = latent_colors[1:]\n",
    "\n",
    "# Load uniform tick props across the whole figure 3\n",
    "with open(os.path.join(\"data\", \"misc\", \"minor_ticks_props.json\"), \"r\") as hd:\n",
    "    props_minorticks = json.load(hd)\n",
    "with open(os.path.join(\"data\", \"misc\", \"major_ticks_props.json\"), \"r\") as hd:\n",
    "    props_majorticks = json.load(hd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log ticks for the EC50 axis\n",
    "ec50lims = (sampled_logec50[0] - sampled_logec50[1]/2, \n",
    "            sampled_logec50[-1] + sampled_logec50[1]/2)\n",
    "minorticks = compute_log_minor_ticks(ec50lims, stp=1, base=10.0)\n",
    "\n",
    "## CREATE FIGURE WITH 4 PANELS ON IT\n",
    "fig, axes = plt.subplots(2, 3)\n",
    "fig.set_size_inches(4.8, 1.65*2)\n",
    "# Leave room for panel D below\n",
    "axes[1, 1].set_axis_off()\n",
    "axes[1, 2].set_axis_off()\n",
    "\n",
    "### PROBABILITY MASS FUNCTION\n",
    "# Make a histogram (bar plot) of the optimal input distribution\n",
    "\n",
    "ax = axes.flat[0]\n",
    "# bar_facecolor = \"xkcd:royal blue\"  # \"xkcd:light grey\"\n",
    "bar_facecolor = \"white\"\n",
    "bars = ax.bar(np.around(sampled_logec50, 2), optim_input_distrib, width=np.diff(sampled_logec50)[0], \n",
    "      color=bar_facecolor, edgecolor=\"k\", linewidth=0.8)\n",
    "\n",
    "# Axes labeling and ticks\n",
    "xlabelprops = dict(size=7, labelpad=0.5)\n",
    "ylabelprops = dict(size=7, labelpad=0.9)\n",
    "xlabelec50 = r\"Antigen $\\mathrm{EC}_{50}$ (#)\"\n",
    "ax.set_xlabel(xlabelec50, **xlabelprops)\n",
    "ax.set_ylabel(r\"$P(\\mathrm{EC}_{50})$\", **ylabelprops)\n",
    "ax.yaxis.set_major_formatter(mpl.ticker.StrMethodFormatter(r\"${x:.1f}$\"))\n",
    "ax.set_yticks([0.0, 0.1, 0.2])\n",
    "x_ticker = mpl.ticker.FuncFormatter(lambda x, pos:\"$10^{}$\".format(int(x)))\n",
    "ax.xaxis.set_major_formatter(x_ticker)\n",
    "majorxticks = [0, 1, 2, 3, 4, 5]\n",
    "ax.set_xticks(majorxticks)\n",
    "ax.set_xticks(minorticks, minor=True)\n",
    "ax.tick_params(which=\"minor\", axis=\"both\", **props_minorticks)\n",
    "ax.tick_params(which=\"major\", axis=\"both\", **props_majorticks)\n",
    "\n",
    "ax.invert_xaxis()\n",
    "\n",
    "# Annotate peptides (include G4)\n",
    "df_potencies = pd.read_json(os.path.join(\"data\", \"misc\", \"potencies_df_2021.json\"))\n",
    "ser_log10ec50s_annot = np.log10(df_potencies).mean(axis=1).loc[[\"N4\", \"A2\", \"Y3\", \"Q4\", \"T4\", \"V4\", \"G4\", \"E1\"]]\n",
    "\n",
    "n_inputs = len(sampled_logec50)\n",
    "maxprob = np.amax(optim_input_distrib)\n",
    "factor = 1.12\n",
    "ax.set_ylim(0, maxprob*factor)\n",
    "previous = ser_log10ec50s_annot.iloc[0] - 1\n",
    "sortpep = ser_log10ec50s_annot.sort_values(ascending=False).index\n",
    "for pep in sortpep:\n",
    "    ha = \"center\"\n",
    "    if abs(ser_log10ec50s_annot[pep] - previous) > 0.7:\n",
    "        lblheight = maxprob*(factor - (factor-1)/3)\n",
    "        previous = ser_log10ec50s_annot[pep]\n",
    "    else:\n",
    "        lblheight = maxprob\n",
    "    ax.annotate(pep, xy=(ser_log10ec50s_annot[pep], lblheight), fontsize=6, ha=ha, va=\"top\", color=\"grey\")\n",
    "    ax.axvline(ser_log10ec50s_annot[pep], ls=\":\", lw=0.8, color=\"grey\", \n",
    "               ymax=ax.transLimits.transform((0, lblheight*0.9))[1])\n",
    "\n",
    "# Annotate capacity\n",
    "#ax.annotate(r\"$C = ({:.2f} \\pm {:.2f})$ bits\".format(capacity_bits, reltol*capacity_bits), \n",
    "#            xy=(0.15, 0.7), xycoords=\"axes fraction\", ha=\"left\", va=\"center\", fontsize=6)\n",
    "\n",
    "\n",
    "### CUMULATIVE DISTRIBUTION SUBPLOT\n",
    "# Make a histogram (bar plot) of the optimal input distribution\n",
    "ax = axes.flat[1]\n",
    "bars = ax.bar(np.around(sampled_logec50, 2)[::-1], cumul_prob, width=np.diff(sampled_logec50)[0], \n",
    "      color=bar_facecolor, edgecolor=\"k\", linewidth=0.8)\n",
    "\n",
    "for i, ii in enumerate(indices):\n",
    "    bars[ii].set_facecolor(colors[-i-1])\n",
    "\n",
    "# Horizontal lines at the bin separators\n",
    "li = ax.axhline(0.5)\n",
    "li.set_visible(False)  # Dummy because the first hline is always wrong\n",
    "hlines_props = dict(ls=\"--\", lw=1.)\n",
    "# Top one: strongest agonist, first color.\n",
    "ax.axhline(1.0-binwidth, **hlines_props, color=colors[0], xmax=ax.transLimits.transform((sampled_logec50[-1], 1))[0])\n",
    "\n",
    "# Intermediate ones, starting from the bottom\n",
    "for i in range(len(binseps)):\n",
    "    ec50_i = sampled_logec50[indices[i+1]]\n",
    "    ax.axhline(binseps[i], **hlines_props, color=colors[-i-2], \n",
    "               xmax=ax.transLimits.transform((ec50_i, 1))[0])\n",
    "\n",
    "# Arrows to show how we are evenly spaced in probability\n",
    "arrowprops = dict(arrowstyle=\"<->\", shrinkA=0.01, shrinkB=0.01, color=\"grey\")\n",
    "ec50_i = sampled_logec50[-1]\n",
    "ax.annotate(\"\", xy=(ec50_i, binseps[0]-binwidth), xytext=(ec50_i, binseps[0]), arrowprops=arrowprops)\n",
    "ax.annotate(\"\", xy=(ec50_i, binseps[-4]), xytext=(ec50_i, binseps[-3]), arrowprops=arrowprops)\n",
    "ax.annotate(\"\", xy=(ec50_i, binseps[-2]), xytext=(ec50_i, binseps[-1]), arrowprops=arrowprops)\n",
    "ax.annotate(\"\", xy=(ec50_i, binseps[-3]), xytext=(ec50_i, binseps[-2]), arrowprops=arrowprops)\n",
    "ax.annotate(\"\", xy=(ec50_i, binseps[-1]), xytext=(ec50_i, binseps[-1]+binwidth), arrowprops=arrowprops)\n",
    "\n",
    "# Remove annoying spines\n",
    "for xi in [\"top\", \"right\"]:\n",
    "    ax.spines[xi].set_visible(False)\n",
    "    ax.spines[xi].set_visible(False)\n",
    "\n",
    "# Tick formatter to have two decimals and align with previous plot\n",
    "def major_formatter(x, pos):\n",
    "    return \"{:.2f}\".format(x)\n",
    "\n",
    "# y axis labeling and ticking\n",
    "ax.set_ylabel(r\"$\\mathrm{CDF}(\\mathrm{EC}_{50})$\", **ylabelprops)\n",
    "ax.yaxis.set_major_formatter(mpl.ticker.FuncFormatter(major_formatter))\n",
    "ax.set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "ax.set_yticklabels(map(str, [0, 0.2, 0.4, 0.6, 0.8, 1.0]))\n",
    "\n",
    "# x axis labeling and ticking\n",
    "ax.set_xlabel(xlabelec50 , **xlabelprops)\n",
    "ax.xaxis.set_major_formatter(x_ticker)\n",
    "ax.set_xticks(majorxticks)\n",
    "ax.set_xticks(minorticks, minor=True)\n",
    "ax.tick_params(which=\"minor\", axis=\"both\", **props_minorticks)\n",
    "ax.tick_params(which=\"major\", axis=\"both\", **props_majorticks)\n",
    "ax.invert_xaxis()\n",
    "\n",
    "### LATENT SPACE OF IDEAL PEPTIDES\n",
    "ax = axes[0, 2]\n",
    "# First plot the many samples we generated\n",
    "for key in df_traj.index:\n",
    "    pep = key[0]\n",
    "    ax.plot(df_traj.loc[key, \"Node 1\"].values, df_traj.loc[key, \"Node 2\"].values, \n",
    "        color=colors_samples_dict[pep], ls=\"-\", lw=0.8)\n",
    "\n",
    "# Plot the means last\n",
    "for pep in df_traj_mean.index:\n",
    "    ecpower = int(np.floor(df_theo_meanparams.loc[pep, \"log10ec50\"]))\n",
    "    ecnumber = 10**(df_theo_meanparams.loc[pep, \"log10ec50\"] - ecpower)\n",
    "    ecnumber = int(round(ecnumber, 0))\n",
    "    if ecnumber == 10:\n",
    "        ecnumber = 1\n",
    "        ecpower += 1\n",
    "    # This is a case where we mainly stay at the origin\n",
    "    if np.amax(np.abs(df_traj_mean.loc[pep, \"Node 1\"].values)) < 0.1:\n",
    "        # Register the line in the legend\n",
    "        ax.plot(df_traj_mean.loc[pep, \"Node 1\"].values[:2], df_traj_mean.loc[pep, \"Node 2\"].values[:2], \n",
    "            color=colors_dict[pep], ls=\"-\", lw=3., \n",
    "            #label=r\"EC${}_{50}=\" + r\"{} \\times 10^{}$\".format(ecnumber, ecpower))\n",
    "            label=r\"${} \\times 10^{}$\".format(ecnumber, ecpower))\n",
    "        # Plot a big dot\n",
    "        ax.plot(df_traj_mean.loc[pep, \"Node 1\"].max(), df_traj_mean.loc[pep, \"Node 2\"].max(), \n",
    "               marker=\"o\", ms=7, ls=\"none\", mfc=colors_dict[pep], mec=colors_dict[pep])\n",
    "    else:\n",
    "        ax.plot(df_traj_mean.loc[pep, \"Node 1\"], df_traj_mean.loc[pep, \"Node 2\"], \n",
    "          color=colors_dict[pep], ls=\"-\", lw=3., \n",
    "          #label=r\"EC${}_{50}=\" + r\"{} \\times 10^{}$\".format(ecnumber, ecpower))\n",
    "          label=r\"${} \\times 10^{}$\".format(ecnumber, ecpower))\n",
    "\n",
    "\n",
    "# Add the spiral EC50 axis\n",
    "ax.plot(df_n1n2_ec50.iloc[:, 0], df_n1n2_ec50.iloc[:, 1], color=(0.3,)*3, lw=1.5, zorder=100)\n",
    "ax.arrow(df_n1n2_ec50.iloc[0, 0], df_n1n2_ec50.iloc[0, 1], \n",
    "         1.5*(df_n1n2_ec50.iloc[0, 0] - df_n1n2_ec50.iloc[1, 0]), \n",
    "         1.5*(df_n1n2_ec50.iloc[0, 1] - df_n1n2_ec50.iloc[1, 1]), color=(0.3,)*3, \n",
    "         shape='full', lw=1.5, length_includes_head=False, head_width=0.4, head_length=0.3, zorder=101)\n",
    "\n",
    "# Markers on that spiral for the selected peptides TODO\n",
    "pep = 0\n",
    "for i in theo_peptides_indices[:-1]:\n",
    "    ax.plot(df_n1n2_ec50.iloc[i, 0], df_n1n2_ec50.iloc[i, 1], marker=\"o\", color=colors_dict[pep], ls=\"none\", mec=(0.3,)*3, mew=0.8, ms=4, zorder=102+pep)\n",
    "    pep += 1\n",
    "\n",
    "# Annotate the time represented by the spiral\n",
    "ax.annotate(r\"$t={}\\,$h\".format(tchoice), \n",
    "            xy=(df_n1n2_ec50.iloc[0, 0]+1.5*(df_n1n2_ec50.iloc[0, 0] - df_n1n2_ec50.iloc[1, 0]),\n",
    "                df_n1n2_ec50.iloc[0, 1]+2.0*(df_n1n2_ec50.iloc[0, 1] - df_n1n2_ec50.iloc[1, 1])), \n",
    "            ha=\"right\", va=\"bottom\", fontsize=7, color=(0.3,)*3\n",
    ")\n",
    "\n",
    "# Legend outside of the plot\n",
    "leg_kwargs = dict(fontsize=6, handlelength=0.8, borderpad=0.3, borderaxespad=0.3, \n",
    "                  frameon=False, labelspacing=0.3, handletextpad=0.5)\n",
    "leg = ax.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0), title=\"Theoretical\\nAntigen\\n\" + r\"EC${}_{50}$ (#)\", \n",
    "          title_fontsize=6, **leg_kwargs)\n",
    "\n",
    "# Remove top and right spines\n",
    "for axis in [\"top\", \"right\"]:\n",
    "    ax.spines[axis].set_visible(False)\n",
    "\n",
    "# Other labeling\n",
    "ls1label = r\"$LS_1$ (a. u.)\"\n",
    "ls2label = r\"$LS_2$ (a. u.)\"\n",
    "ax.set_xlabel(ls1label, **xlabelprops)\n",
    "ax.set_ylabel(ls2label, **ylabelprops)\n",
    "ax.set_xticks([0])\n",
    "ax.set_yticks([0])\n",
    "ax.set_xticklabels([0])\n",
    "ax.set_yticklabels([0])\n",
    "\n",
    "### PANEL D: N1 AND N2 AS A FUNCTION OF EC50\n",
    "ax = axes[1, 0]\n",
    "# Horizontal lines marking the theoretical antigen classes\n",
    "for pep, i in enumerate(theo_peptides_indices):\n",
    "    ax.axvline(x=10**df_n1n2_ec50.iloc[i, 2], color=colors_dict[pep], linestyle='--', lw=2.)\n",
    "\n",
    "# Plot N1 and N2 at tchoice vs Ec50\n",
    "for i in range(2):\n",
    "    lbl = ls1label[:-8] if i == 0 else ls2label[:-8]\n",
    "    ax.plot(10**df_n1n2_ec50.iloc[:, 2], df_n1n2_ec50.iloc[:, i], label=lbl, \n",
    "            color=nodePalette[i], lw=2.5)\n",
    "\n",
    "# Mark the ideal peptides\n",
    "# Markers on that spiral for the selected peptides TODO\n",
    "pep = 0\n",
    "for i in theo_peptides_indices:\n",
    "    ax.plot(10**df_n1n2_ec50.iloc[i, 2], df_n1n2_ec50.iloc[i, 0], marker=\"o\", color=colors_dict[pep], ls=\"none\", mec='k', mew=0.8, ms=6)\n",
    "    if pep < len(theo_peptides_indices)-1:\n",
    "        ax.plot(10**df_n1n2_ec50.iloc[i, 2], df_n1n2_ec50.iloc[i, 1], marker=\"o\", color=colors_dict[pep], ls=\"none\", mec='k', mew=0.8, ms=6)\n",
    "    pep += 1\n",
    "\n",
    "# Labeling, etc.\n",
    "for axis in [\"top\", \"right\"]:\n",
    "    ax.spines[axis].set_visible(False)\n",
    "ax.set_xlabel(r\"Antigen EC$_{50}$ (#)\", fontsize=7, labelpad=1)\n",
    "ax.set_ylabel(\"Latent Space (a. u.)\", fontsize=7, labelpad=1)\n",
    "ax.set_yticks([0])\n",
    "ax.set_yticklabels([0])\n",
    "\n",
    "ax.set_xscale('log')\n",
    "locmin = mpl.ticker.LogLocator(base=10.0,subs=np.linspace(0.1,0.9,num=9,endpoint=True).tolist(),numticks=50)\n",
    "ax.xaxis.set_minor_locator(locmin)\n",
    "ax.xaxis.set_minor_formatter(mpl.ticker.NullFormatter())\n",
    "xticks = [10**5,10**4,10**3,10**2,10**1,10**0]\n",
    "xticklabels = ['10$^{'+str(int(np.log10(x)))+'}$' for x in xticks]\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xticklabels)\n",
    "ax.tick_params(which=\"minor\", axis=\"both\", **props_minorticks)\n",
    "ax.tick_params(which=\"major\", axis=\"both\", **props_majorticks)\n",
    "ax.invert_xaxis()\n",
    "ax.set_xlabel('Antigen EC$_{50}$ (#)')\n",
    "\n",
    "leg_kwargs = dict(fontsize=7 , handlelength=0.8, borderpad=0.5, borderaxespad=0.3, \n",
    "                  frameon=True, labelspacing=0.3, handletextpad=0.5, framealpha=0.9)\n",
    "leg2 = ax.legend(**leg_kwargs)\n",
    "\n",
    "\n",
    "fig.tight_layout(w_pad=0.4, h_pad=3.)\n",
    "#fig.savefig(os.path.join(\"figures\", \"capacity\", \"fig3CD_probability_cumulative_latentspace_N1N2vsEC50.pdf\"), \n",
    "#           transparent=True, bbox_inches=\"tight\", bbox_extra_artists=(leg, leg2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary figure: parameter space of theoretical antigen classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Generate parameter space samples\n",
    "rndgen = np.random.RandomState(seed=53739)\n",
    "nsamples2 = 72\n",
    "df_theo_samples2 = pd.DataFrame(np.zeros([nsamples2*n_categories, 7]), \n",
    "                        index=pd.MultiIndex.from_product([range(n_categories), range(nsamples2)], \n",
    "                            names=[\"TheoreticalPeptide\", \"Sample\"]), \n",
    "                        columns=df_theo_meanparams.columns)\n",
    "for i in range(n_categories):\n",
    "    # Generate nsamples parameter samples for each peptide\n",
    "    df_theo_samples2.loc[i].iloc[:, :3] = np.clip(rndgen.multivariate_normal(\n",
    "        interpolated_means[theo_peptides_indices[i]], \n",
    "        interpolated_covmats[theo_peptides_indices[i]], nsamples2), \n",
    "        a_min=[0.0, 0.0, -np.pi], a_max=None)\n",
    "    \n",
    "    for j, pch in zip((3, 4, 5), (\"v1\", \"alpha\", \"beta\")):\n",
    "        df_theo_samples2.loc[i].iloc[:, j] = np.clip(rndgen.normal(\n",
    "            theo_peptides_par_means[pch][i], theo_peptides_par_varis[pch][i], nsamples2), a_min=0.02, a_max=None)\n",
    "    \n",
    "    df_theo_samples2.loc[i].iloc[:, 6] = theo_peptides_log10ec50s[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameter space distributions of theoretical antigen classes\n",
    "# Use df_theo_samples? Or generate more than 32 samples\n",
    "# Highlight df_theo_meanparams with a larger point. \n",
    "# Use the same color maps as above. colors_dict, colors_samples_dict\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(2., 1.75)\n",
    "\n",
    "# First plot the many samples we generated\n",
    "# We plot theta vs tau0? Or a0 vs theta, or a0 vs tau0? Try them all\n",
    "p_sel = [\"a0\", \"theta\"]\n",
    "for pep in df_traj.index.get_level_values(\"TheoreticalPeptide\").unique():\n",
    "    ax.plot(df_theo_samples2.loc[pep, p_sel[0]].values, df_theo_samples2.loc[pep, p_sel[1]].values, \n",
    "         marker=\"o\", mfc=colors_samples_dict[pep], mec=colors_dict[pep], ls=\"none\", ms=3, alpha=0.7)\n",
    "\n",
    "# Plot the means last\n",
    "for pep in df_traj_mean.index:\n",
    "    ecpower = int(np.floor(df_theo_meanparams.loc[pep, \"log10ec50\"]))\n",
    "    ecnumber = 10**(df_theo_meanparams.loc[pep, \"log10ec50\"] - ecpower)\n",
    "    ecnumber = round(ecnumber, 1)\n",
    "    ax.plot(df_theo_meanparams.loc[pep, p_sel[0]], df_theo_meanparams.loc[pep, p_sel[1]], \n",
    "        mfc=colors_dict[pep], mec=\"k\", mew=1., ls=\"none\", marker=\"o\", ms=6, \n",
    "        label=r\"EC${}_{50}=\" + r\"{} \\times 10^{}$\".format(ecnumber, ecpower))\n",
    "\n",
    "# Add a legend\n",
    "split_legend = True\n",
    "if not split_legend:\n",
    "    dict(fontsize=6, handlelength=1., borderpad=0.3, frameon=False, labelspacing=0.2)\n",
    "    ax.legend(**leg_kwargs)\n",
    "\n",
    "else:\n",
    "    # Create a split legend for the average lines. \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "    handsplit = 2\n",
    "    leg_kwargs = dict(fontsize=6, handlelength=1., borderpad=0.3, frameon=True, \n",
    "                      labelspacing=0.2, markerscale=0.75, handletextpad=0.3)\n",
    "    first_legend = plt.legend(handles=handles[:handsplit], labels=labels[:handsplit], \n",
    "                        loc='upper left', bbox_to_anchor=(0, 1.05), **leg_kwargs)\n",
    "\n",
    "    # Add the legend manually to the current Axes.\n",
    "    ax.add_artist(first_legend)\n",
    "\n",
    "    # Create another legend for the second line.\n",
    "    second_legend = plt.legend(handles=handles[handsplit:], labels=labels[handsplit:], \n",
    "                        loc='lower right', bbox_to_anchor=(1.02, 0), **leg_kwargs)\n",
    "    ax.add_artist(second_legend)\n",
    "\n",
    "# Remove top and right spines\n",
    "for axis in [\"top\", \"right\"]:\n",
    "    ax.spines[axis].set_visible(False)\n",
    "\n",
    "# Other labeling\n",
    "ax.set_xlabel(r\"${}$\".format(p_sel[0]), fontsize=7)\n",
    "ax.set_ylabel(r\"$\\{}$\".format(p_sel[1]), fontsize=7)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# Uncomment to save figure\n",
    "#fig.savefig(os.path.join(\"figures\", \"capacity\", \"supp_panel_theo_peptide_ballistic_param_space.pdf\"), \n",
    "#            transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstructing the cytokine trajectories of theoretical antigen classes\n",
    "### Import some results, compute latent space concentration trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import reconstruction objects\n",
    "folder = os.path.join(\"results\", \"reconstruction\")\n",
    "with open(os.path.join(folder, \"quadratic_tanh_pipeline_HighMI_1.pkl\"), \"rb\") as hd:\n",
    "    pipe = pickle.load(hd)\n",
    "tanh_norm_factors = pd.read_hdf(os.path.join(folder, \"tanh_norm_factors_integrals_HighMI_1.hdf\"))\n",
    "tanh_norm_factors = df_traj.stack(\"Time\").mean(axis=0)\n",
    "print(tanh_norm_factors)\n",
    "\n",
    "# Also import v2/v1 ratios\n",
    "ser_v2v1 = pd.read_hdf(os.path.join(\"results\", \"fits\", \"df_v2v1_Sigmoid_freealpha_HighMI_13.hdf\"))\n",
    "ser_v2v1 = pd.concat([ser_v2v1.iloc[0:1]]*len(df_theo_meanparams.index), \n",
    "            keys=df_theo_meanparams.index.get_level_values(\"TheoreticalPeptide\"), names=[\"TheoreticalPeptide\"])\n",
    "ser_v2v1 = ser_v2v1.reorder_levels([1, 0])\n",
    "# Compute latent space curves from parameters, since the function compute_latent_curves\n",
    "# automatically includes the tanh normalized integrals, which saves some code here. \n",
    "times = df_traj.columns.get_level_values(\"Time\").unique().astype(float).values\n",
    "df_latent_synth = compute_latent_curves(df_theo_meanparams.iloc[:, :6], ser_v2v1, tanh_norm_factors, times,\n",
    "    model=\"Sigmoid_freealpha\", tsc=tscale)\n",
    "\n",
    "df_traj_conc = df_traj_mean.stack(\"Node\").diff(axis=1).unstack(\"Node\").stack(\"Time\")\n",
    "\n",
    "sns.relplot(data=df_traj_conc.stack(\"Node\").reset_index(), col=\"Node\", x=\"Time\", y=0, \n",
    "            hue=\"TheoreticalPeptide\", kind=\"line\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cytokine order\n",
    "df_min, df_max = pd.read_pickle(os.path.join(\"data\", \"trained-networks\", \"min_max-thomasRecommendedTraining.pkl\"))\n",
    "df_min, df_max = df_min.xs(\"integral\", level=\"Feature\"), df_max.xs(\"integral\", level=\"Feature\")\n",
    "cyto_order = df_min.index.get_level_values(\"Cytokine\")\n",
    "print(cyto_order)\n",
    "\n",
    "# Reconstruct!\n",
    "df_recon_synth = pd.DataFrame(pipe.predict(df_latent_synth), index=df_latent_synth.index, \n",
    "                             columns=cyto_order)\n",
    "df_recon_synth = np.clip(df_recon_synth, a_min=0, a_max=None)\n",
    "\n",
    "# Stack some reconstruction results\n",
    "levels_to_stack = list(df_recon_synth.index.names)\n",
    "levels_to_stack.remove(\"Time\")\n",
    "df_integrals = (df_recon_synth.copy().unstack(levels_to_stack).sort_index()\n",
    "                .cumsum(axis=0).stack(levels_to_stack).unstack(\"Time\").stack(\"Time\"))\n",
    "df_recon_combined = pd.concat({\"concentration\":df_recon_synth, \"integral\":df_integrals}, \n",
    "                             axis=1, names=[\"Feature\", \"Cytokine\"])\n",
    "\n",
    "# Scale back \n",
    "df_recon_combined = scale_back(df_recon_combined, df_min, df_max)\n",
    "\n",
    "# Minimum offset\n",
    "datalist = [\"cytokineConcentrationPickleFile-20210619-HighMI_13_corrected-final.pkl\"]\n",
    "df_raw_data, df_nM_min_conc =  import_folder_naive_data(os.path.join(\"data\", \"final\"), datalist)\n",
    "\n",
    "# Retrive the minimum concentration in HighMI_1 for proper scaling back\n",
    "# This is a constant: log(cyto/min) = log(cyto/units) - log(min/units)\n",
    "# that we will add back to all data before plotting\n",
    "dset_choice = \"HighMI_13_corrected\"\n",
    "pM_offset = 1000 * df_nM_min_conc.loc[dset_choice]\n",
    "\n",
    "# Add the offset\n",
    "df_recon_combined[\"concentration\"] = df_recon_combined[\"concentration\"] + np.log10(pM_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the reconstructions (y axis is log10(pM))\n",
    "sns.relplot(data=df_recon_combined[\"concentration\"].stack(\"Cytokine\").reset_index(), x=\"Time\", y=0, \n",
    "    col=\"Cytokine\", hue=\"TheoreticalPeptide\", height=2.5, kind=\"line\", \n",
    "    palette=sns.color_palette(n_colors=len(df_recon_synth.index.get_level_values(\"TheoreticalPeptide\").unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to save the results, which are used (integrals) in main figure 3E\n",
    "#df_recon_combined.to_hdf(os.path.join(\"results\", \"capacity\", \n",
    "#    \"theoretical_antigen_reconstruction_conc_integrals_HighMI13.hdf\"), key=\"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
