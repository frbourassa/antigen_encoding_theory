{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting dynamical models in latent space\n",
    "To run this notebook, you need:\n",
    "- Pre-processed cytokine time series in the `data/processed/` folder\n",
    "- the input weights of a neural network and the min and max cytokine concentrations used to scale the data, in `data/trained-networks`. \n",
    "Those files are available in the data repository hosted online, or you can generate them yourself from raw cytokine data using [`cytokine-pipeline`](https://github.com/tjrademaker/cytokine-pipeline). \n",
    "\n",
    "## Definition of the different models \n",
    "### Notation\n",
    "$LS_1, LS_2$: cytokine concentrations projected in latent space\n",
    "\n",
    "$ LS_1, LS_2$: cytokine integrals projected in latent space\n",
    "\n",
    "## Constant velocity model\n",
    "See supplementary information\n",
    "\n",
    "## Constant force model\n",
    "Intermediate model between constant velocity and force model with matching; removed from the paper. \n",
    "\n",
    "## Force model with matching (\"Sigmoid\")\n",
    "There are two versions: \"Sigmoid_freealpha\", in which kinetic rate paraemters $\\alpha$ and $\\beta$ are fitted separately, and \"Sigmoid_fixalpha\", in which $\\alpha = \\frac{1}{20} \\,  \\mathrm{h^{-1}}$ and $\\gamma = \\beta / \\alpha$ is fitted. \n",
    "\n",
    "### Equations for $LS_1$, $LS_2$\n",
    "Similar for both nodes, but to capture the initial dip in node 2, we need to square the bounded exponential of the first phase\n",
    "\n",
    "$$ LS_1(t) = \\left(1 - e^{-\\alpha t} \\right) \\left( \\frac{a_0 \\cos{\\theta} + v_1}{e^{\\beta(t - t_0)} + 1} - v_1 \\right)$$\n",
    "\n",
    "$$ LS_2(t) = \\left(1 - e^{-\\alpha t} \\right) \\left( \\frac{(a_0 \\sin{\\theta} + v_2)(1 - e^{-\\alpha t})}{e^{\\beta(t - t_0)} + 1} - v_2 \\right)$$\n",
    "\n",
    "### Equations for $LS_1$, $LS_2$\n",
    "It is possible to integrate analytically, so we can fit integrals first. Define $\\tau = \\alpha t$, $\\tau_0 = \\alpha t_0$, and $\\gamma = \\beta / \\alpha$. The result is\n",
    "\n",
    "\n",
    "$$ LS_1(t) = \\frac{a_0 \\cos{\\theta}+ v_1}{\\alpha} \\left( I(\\tau, \\tau_0, \\gamma) - \\frac{1}{\\gamma} \\ln{\\left(e^{-\\gamma \\tau} + e^{-\\gamma \\tau_0}  \\right)} \\right)  \n",
    "- \\frac{v_1}{\\alpha} \\left(\\tau + e^{-\\tau} \\right) + K_1 $$\n",
    "\n",
    "$$ LS_2(t) = \\frac{a_0 \\sin{\\theta} + v_2}{\\alpha} \\left( 2I(\\tau, \\tau_0, \\gamma) - \\tfrac12 I(2 \\tau, 2\\tau_0, \\tfrac{\\gamma}{2}) - \\tfrac{1}{\\gamma} \\ln{\\left(e^{-\\gamma \\tau} + e^{-\\gamma \\tau_0}  \\right)} \\right)  \n",
    "- \\frac{v_2}{\\alpha} \\left(\\tau + e^{-\\tau} \\right) + K_2 $$ \n",
    "\n",
    "where the $K_i$ are chosen to ensure $LS_i(0) = 0$. The complicated part is the integral $I(\\tau, \\tau_0, \\gamma)$, which is\n",
    "\n",
    "$$ I(\\tau, \\tau_0, \\gamma) = \\int \\mathrm{d} \\tau \\frac{-e^{-\\tau}}{e^{\\gamma (\\tau - \\tau_0) }+ 1} $$\n",
    "\n",
    "The special case $\\frac{1}{\\gamma} \\in \\mathbb{N}^+$ can be solved using partial fractions:\n",
    "\n",
    "\n",
    "$$ I(\\tau) = e^{-\\tau} + e^{-\\tau} \\sum_{j=1}^{n-1} \\frac{n}{n-j} (-1)^j e^{(\\tau - \\tau_0)\\frac{j}{n}} \\\\\n",
    "+ (-1)^n n e^{-\\tau_0} \\ln{ \\left(e^{-\\tau/n} + e^{-\\tau_0 / n} \\right)} $$\n",
    "\n",
    "For the general case, Mathematica suggests the following answer, valid  when $\\frac{1}{\\gamma} \\notin \\mathbb{N}^+$:\n",
    "\n",
    "$$ I(\\tau) = e^{-\\tau} {}_2F_1(1, \\frac{-1}{\\gamma}; 1 - \\frac{1}{\\gamma}; -e^{\\gamma(\\tau - \\tau_0)}) $$\n",
    "\n",
    "where ${}_2F_1$ is Gauss' hypergeometric function. This result can be derived from ${}_2F_1(0, b; c; z) =1$ and from the recurrence relation \n",
    "(NIST's *Digital Library of Mathematical Formulas*, eq. 15.5.20)\n",
    "\n",
    "$$ z(1-z) \\frac{d}{dz} {}_2F_1(a, b; c; z) = (c-a) \\, {}_2F_1(a-1, b; c; z) \\\\ + (a -c +bz) \\, {}_2F_1(a, b; c; z) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pickle\n",
    "import sys, os\n",
    "from time import perf_counter  # For timing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltspcyt.scripts.adapt_dataframes import set_standard_order, sort_SI_column\n",
    "from ltspcyt.scripts.latent_space import import_mutant_output\n",
    "from ltspcyt.scripts.neural_network import import_WT_output\n",
    "\n",
    "# Curve fitting functions\n",
    "from ltspcyt.scripts.sigmoid_ballistic import return_param_and_fitted_latentspace_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import seterr as special_seterr\n",
    "special_seterr(loss=\"warn\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptides=[\"N4\", \"Q4\", \"T4\", \"V4\", \"G4\", \"E1\", \"A2\", \"Y3\", \"A8\", \"Q7\"]\n",
    "concentrations=[\"1uM\",\"100nM\",\"10nM\",\"1nM\"]\n",
    "fit_vars={\"Constant velocity\":[\"v0\",\"t0\",\"theta\",\"vt\"],\"Constant force\":[\"F\",\"t0\",\"theta\",\"vt\"],\n",
    "         \"Sigmoid\":[\"a0\", \"tau0\", \"theta\", \"v1\", \"gamma\"], \n",
    "         \"Sigmoid_freealpha\":[\"a0\", \"tau0\", \"theta\", \"v1\", \"alpha\", \"beta\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data and neural network parts needed to fit models\n",
    "df_WT = import_WT_output()\n",
    "minmaxfile = os.path.join(\"data\", \"trained-networks\", \"min_max-thomasRecommendedTraining.hdf\")\n",
    "df_min = pd.read_hdf(minmaxfile, key=\"df_min\")\n",
    "df_max = pd.read_hdf(minmaxfile, key=\"df_max\")\n",
    "projmat = np.load(os.path.join(\"data\", \"trained-networks\", \"mlp_input_weights-thomasRecommendedTraining.npy\"))\n",
    "print(df_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cytokines=df_min.index.get_level_values(\"Cytokine\")\n",
    "times=np.arange(1,73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_WT.unstack(\"Time\").loc[:,(\"integral\",cytokines,times)].stack(\"Time\")\n",
    "df=(df - df_min)/(df_max - df_min)\n",
    "df_proj=pd.DataFrame(np.dot(df, projmat),index=df.index,columns=[\"Node 1\",\"Node 2\"])\n",
    "df_proj.columns.name = \"Node\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Defining the dataset(s) to use\n",
    "# Multiple datasets to populate parameter space better\n",
    "# Activation_2 is the 100k T cells condition of old combined experiment Activation_TCellNumber_1, \n",
    "# the naive data of which is in TCellNumber_3. Hence, they share the same data for 100k naive T cells. \n",
    "# Need only TCellNumber 3, do not use Activation_2 unless you want to look at blast cells specifically. \n",
    "subset_exp = [\n",
    "    \"Activation_1\", \"Activation_3\",  \n",
    "    \"PeptideComparison_1\", \"PeptideComparison_2\", \"PeptideComparison_3\", \"PeptideComparison_4\",\n",
    "    \"TCellNumber_1\", \"TCellNumber_2\", \"TCellNumber_3\", \"TCellNumber_4\",\n",
    "    \"HighMI_1-1\", \"HighMI_1-2\", \"HighMI_1-3\", \"HighMI_1-4\"\n",
    "]\n",
    "df_proj_exp = df_proj.loc[subset_exp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model choice and curve fit of that model\n",
    "# Advice: run twice, once with \"Sigmoid_freealpha\" and regul_rate = 0.4\n",
    "# once with \"Constant_velocity\" and regul_rate = 1.0\n",
    "# Save both dataframes of fitted parameters, they are used in other parts of this project. \n",
    "# There is also a supplementary figure using fits from Sigmoid (fixed alpha), regul_rate 0.4. \n",
    "# (to show the impact of fitting alpha too or keeping it constant)\n",
    "\n",
    "fit = \"Sigmoid_freealpha\"\n",
    "#fit = \"Sigmoid\"\n",
    "regul_rate = 0.4\n",
    "#fit = \"Constant velocity\"\n",
    "#regul_rate = 1.0\n",
    "\n",
    "# File names specification for that model and regularization rate\n",
    "name_specs = \"{}_reg{}\".format(fit.replace(\" \", \"_\"), str(round(regul_rate, 2)).replace(\".\", \"\"))\n",
    "\n",
    "start_time = perf_counter()\n",
    "\n",
    "ret = return_param_and_fitted_latentspace_dfs(df_proj_exp, fit, reg_rate=regul_rate)\n",
    "df_params, df_compare, df_hess, df_v2v1 = ret\n",
    "\n",
    "end_t = perf_counter()\n",
    "print(\"Time to fit: \", perf_counter() - start_time)\n",
    "del start_time\n",
    "\n",
    "nparameters = len(fit_vars[fit])\n",
    "print(df_hess.median())  # Hessian matrix: inverse of the covariance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = subset_exp[1]  # Select the data set to plot here\n",
    "tcellnum = \"100k\"\n",
    "df_compare_sel = df_compare.xs(tcellnum, level=\"TCellNumber\", axis=0).xs(dataset, level=\"Data\", axis=0)\n",
    "print(df_compare_sel.index.names)\n",
    "df_compare_sel.columns.names = [\"Variable\"]\n",
    "data=df_compare_sel.loc[(peptides,concentrations,slice(None),slice(None),\"concentration\"),:]\n",
    "h=sns.relplot(data=data.stack().reset_index(),x=\"Time\",y=0,kind=\"line\",sort=False,\n",
    "            hue=\"Peptide\",hue_order=peptides,\n",
    "            col=\"Concentration\",col_order=concentrations,row=\"Variable\",\n",
    "            style=\"Processing type\", height=3.5)\n",
    "#h.fig.savefig(os.path.join(\"figures\", \"fits\", \n",
    "#   \"concentrations_{}_{}.pdf\".format(name_specs, dataset)), transparent=True)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the fit of integrals vs time\n",
    "data=df_compare_sel.loc[(peptides,concentrations,slice(None),slice(None),\"integral\"),:]\n",
    "h=sns.relplot(data=data.stack().reset_index(),x=\"Time\",y=0,kind=\"line\",sort=False,\n",
    "            hue=\"Peptide\",hue_order=peptides,\n",
    "            col=\"Concentration\",col_order=concentrations,row=\"Variable\",\n",
    "            style=\"Processing type\", height=3.5)\n",
    "#h.fig.savefig(os.path.join(\"figures\", \"fits\", \n",
    "#   \"integrals_{}_{}.pdf\".format(name_specs, dataset)), transparent=True)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the latent space ballistic trajectories LS_1 vs LS_2\n",
    "data=df_compare_sel.loc[(peptides,concentrations,slice(None),slice(None),\"integral\"),:]\n",
    "h=sns.relplot(data=data.reset_index(), x=\"Node 1\",y=\"Node 2\", kind=\"line\", sort=False,\n",
    "            hue=\"Peptide\",hue_order=peptides,\n",
    "            size=\"Concentration\",size_order=concentrations,\n",
    "            style=\"Processing type\")\n",
    "#h.fig.savefig(os.path.join(\"figures\", \"fits\", \n",
    "#   \"LS1_vs_LS2_{}_{}.pdf\".format(name_specs, dataset)), transparent=True)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to save df_compare and df_params to be reused elsewhere for plotting, e.g. main_plotting_scripts/\n",
    "#df_compare.to_hdf(os.path.join(\"results\", \"fits\", \"df_compare_{}_selectdata.hdf\".format(name_specs)), key=\"df_compare\", mode=\"w\")\n",
    "#df_params.to_hdf(os.path.join(\"results\", \"fits\", \"df_params_{}_selectdata.hdf\".format(name_specs)), key=\"df_params\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
